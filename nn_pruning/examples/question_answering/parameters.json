{
  "model_name_or_path": "bert-large-uncased",
  "dataset_name": "squad",
  "do_train": 1,
  "do_eval": 1,
  "per_device_train_batch_size": 8,
  "max_seq_length": 384,
  "doc_stride": 128,
  "num_train_epochs": 20,
  "logging_steps": 250,
  "save_steps": 10000,
  "eval_steps": 10000,
  "save_total_limit": 50,
  "seed": 17,
  "evaluation_strategy": "steps",
  "learning_rate": 3e-5,
  "mask_scores_learning_rate": 1e-2,
  "output_dir":  "/data_2to/devel_data/nn_pruning/output/squad_test_large/",
  "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_large/",
  "overwrite_cache": 0,
  "overwrite_output_dir": 1,
  "warmup_steps": 5400,
  "initial_warmup": 1,
  "final_warmup": 10,
  "initial_threshold": 0,
  "final_threshold": 0.1,
  "dense_pruning_method": "sigmoied_threshold:1d_alt",
  "dense_block_rows":1,
  "dense_block_cols":1,
  "dense_lambda":0.25,
  "attention_pruning_method": "sigmoied_threshold",
  "attention_block_rows":32,
  "attention_block_cols":32,
  "attention_lambda":1.0,
  "ampere_pruning_method": "disabled",
  "mask_init": "constant",
  "mask_scale": 0.0,
  "regularization": "l1",
  "regularization_final_lambda": 60,
  "distil_teacher_name_or_path":"bert-large-uncased-whole-word-masking-finetuned-squad",
  "distil_alpha_ce": 0.1,
  "distil_alpha_teacher": 0.9,
  "attention_output_with_dense": 0
}
