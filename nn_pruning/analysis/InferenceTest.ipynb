{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed heads 101, total_heads=144, percentage removed=0.7013888888888888\n",
      "bert.encoder.layer.0.intermediate.dense, sparsity = 93.33\n",
      "bert.encoder.layer.0.output.dense, sparsity = 93.33\n",
      "bert.encoder.layer.1.intermediate.dense, sparsity = 90.49\n",
      "bert.encoder.layer.1.output.dense, sparsity = 90.49\n",
      "bert.encoder.layer.2.intermediate.dense, sparsity = 86.95\n",
      "bert.encoder.layer.2.output.dense, sparsity = 86.95\n",
      "bert.encoder.layer.3.intermediate.dense, sparsity = 86.30\n",
      "bert.encoder.layer.3.output.dense, sparsity = 86.30\n",
      "bert.encoder.layer.4.intermediate.dense, sparsity = 84.80\n",
      "bert.encoder.layer.4.output.dense, sparsity = 84.80\n",
      "bert.encoder.layer.5.intermediate.dense, sparsity = 86.10\n",
      "bert.encoder.layer.5.output.dense, sparsity = 86.10\n",
      "bert.encoder.layer.6.intermediate.dense, sparsity = 89.78\n",
      "bert.encoder.layer.6.output.dense, sparsity = 89.78\n",
      "bert.encoder.layer.7.intermediate.dense, sparsity = 90.79\n",
      "bert.encoder.layer.7.output.dense, sparsity = 90.79\n",
      "bert.encoder.layer.8.intermediate.dense, sparsity = 94.43\n",
      "bert.encoder.layer.8.output.dense, sparsity = 94.43\n",
      "bert.encoder.layer.9.intermediate.dense, sparsity = 98.11\n",
      "bert.encoder.layer.9.output.dense, sparsity = 98.11\n",
      "bert.encoder.layer.10.intermediate.dense, sparsity = 97.43\n",
      "bert.encoder.layer.10.output.dense, sparsity = 97.43\n",
      "bert.encoder.layer.11.intermediate.dense, sparsity = 95.05\n",
      "bert.encoder.layer.11.output.dense, sparsity = 95.05\n",
      "Reduction of linear layers: 6.294419220154082\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering\n",
    "from nn_pruning.inference_model_patcher import optimize_model\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"madlag/bert-base-uncased-squad1.1-pruned-x3.2-v2\")\n",
    "\n",
    "def compute_size(model):\n",
    "    elems = 0\n",
    "    for k, v in model.named_parameters():\n",
    "        if \"LayerNorm\" not in k and \"encoder\" in k:\n",
    "            elems += v.numel()\n",
    "    return elems\n",
    "\n",
    "original_count = compute_size(model)\n",
    "\n",
    "# Create a model patcher\n",
    "model = optimize_model(model, mode=\"dense\", clone=False)\n",
    "\n",
    "new_count = compute_size(model)\n",
    "\n",
    "\n",
    "print(\"Reduction of linear layers:\", original_count / new_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.encoder.layer.0.attention.self.query.weight torch.Size([448, 768])\n",
      "bert.encoder.layer.0.attention.self.query.bias torch.Size([448])\n",
      "bert.encoder.layer.0.attention.self.key.weight torch.Size([448, 768])\n",
      "bert.encoder.layer.0.attention.self.key.bias torch.Size([448])\n",
      "bert.encoder.layer.0.attention.self.value.weight torch.Size([448, 768])\n",
      "bert.encoder.layer.0.attention.self.value.bias torch.Size([448])\n",
      "bert.encoder.layer.0.attention.output.dense.weight torch.Size([768, 448])\n",
      "bert.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.0.intermediate.dense.linear.weight torch.Size([205, 768])\n",
      "bert.encoder.layer.0.intermediate.dense.linear.bias torch.Size([205])\n",
      "bert.encoder.layer.0.output.dense.linear.weight torch.Size([768, 205])\n",
      "bert.encoder.layer.0.output.dense.linear.bias torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.query.weight torch.Size([128, 768])\n",
      "bert.encoder.layer.1.attention.self.query.bias torch.Size([128])\n",
      "bert.encoder.layer.1.attention.self.key.weight torch.Size([128, 768])\n",
      "bert.encoder.layer.1.attention.self.key.bias torch.Size([128])\n",
      "bert.encoder.layer.1.attention.self.value.weight torch.Size([128, 768])\n",
      "bert.encoder.layer.1.attention.self.value.bias torch.Size([128])\n",
      "bert.encoder.layer.1.attention.output.dense.weight torch.Size([768, 128])\n",
      "bert.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.1.intermediate.dense.linear.weight torch.Size([292, 768])\n",
      "bert.encoder.layer.1.intermediate.dense.linear.bias torch.Size([292])\n",
      "bert.encoder.layer.1.output.dense.linear.weight torch.Size([768, 292])\n",
      "bert.encoder.layer.1.output.dense.linear.bias torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.query.weight torch.Size([448, 768])\n",
      "bert.encoder.layer.2.attention.self.query.bias torch.Size([448])\n",
      "bert.encoder.layer.2.attention.self.key.weight torch.Size([448, 768])\n",
      "bert.encoder.layer.2.attention.self.key.bias torch.Size([448])\n",
      "bert.encoder.layer.2.attention.self.value.weight torch.Size([448, 768])\n",
      "bert.encoder.layer.2.attention.self.value.bias torch.Size([448])\n",
      "bert.encoder.layer.2.attention.output.dense.weight torch.Size([768, 448])\n",
      "bert.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.2.intermediate.dense.linear.weight torch.Size([401, 768])\n",
      "bert.encoder.layer.2.intermediate.dense.linear.bias torch.Size([401])\n",
      "bert.encoder.layer.2.output.dense.linear.weight torch.Size([768, 401])\n",
      "bert.encoder.layer.2.output.dense.linear.bias torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.query.weight torch.Size([320, 768])\n",
      "bert.encoder.layer.3.attention.self.query.bias torch.Size([320])\n",
      "bert.encoder.layer.3.attention.self.key.weight torch.Size([320, 768])\n",
      "bert.encoder.layer.3.attention.self.key.bias torch.Size([320])\n",
      "bert.encoder.layer.3.attention.self.value.weight torch.Size([320, 768])\n",
      "bert.encoder.layer.3.attention.self.value.bias torch.Size([320])\n",
      "bert.encoder.layer.3.attention.output.dense.weight torch.Size([768, 320])\n",
      "bert.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.3.intermediate.dense.linear.weight torch.Size([421, 768])\n",
      "bert.encoder.layer.3.intermediate.dense.linear.bias torch.Size([421])\n",
      "bert.encoder.layer.3.output.dense.linear.weight torch.Size([768, 421])\n",
      "bert.encoder.layer.3.output.dense.linear.bias torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.query.weight torch.Size([256, 768])\n",
      "bert.encoder.layer.4.attention.self.query.bias torch.Size([256])\n",
      "bert.encoder.layer.4.attention.self.key.weight torch.Size([256, 768])\n",
      "bert.encoder.layer.4.attention.self.key.bias torch.Size([256])\n",
      "bert.encoder.layer.4.attention.self.value.weight torch.Size([256, 768])\n",
      "bert.encoder.layer.4.attention.self.value.bias torch.Size([256])\n",
      "bert.encoder.layer.4.attention.output.dense.weight torch.Size([768, 256])\n",
      "bert.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.4.intermediate.dense.linear.weight torch.Size([467, 768])\n",
      "bert.encoder.layer.4.intermediate.dense.linear.bias torch.Size([467])\n",
      "bert.encoder.layer.4.output.dense.linear.weight torch.Size([768, 467])\n",
      "bert.encoder.layer.4.output.dense.linear.bias torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.query.weight torch.Size([192, 768])\n",
      "bert.encoder.layer.5.attention.self.query.bias torch.Size([192])\n",
      "bert.encoder.layer.5.attention.self.key.weight torch.Size([192, 768])\n",
      "bert.encoder.layer.5.attention.self.key.bias torch.Size([192])\n",
      "bert.encoder.layer.5.attention.self.value.weight torch.Size([192, 768])\n",
      "bert.encoder.layer.5.attention.self.value.bias torch.Size([192])\n",
      "bert.encoder.layer.5.attention.output.dense.weight torch.Size([768, 192])\n",
      "bert.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.5.intermediate.dense.linear.weight torch.Size([427, 768])\n",
      "bert.encoder.layer.5.intermediate.dense.linear.bias torch.Size([427])\n",
      "bert.encoder.layer.5.output.dense.linear.weight torch.Size([768, 427])\n",
      "bert.encoder.layer.5.output.dense.linear.bias torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.query.weight torch.Size([256, 768])\n",
      "bert.encoder.layer.6.attention.self.query.bias torch.Size([256])\n",
      "bert.encoder.layer.6.attention.self.key.weight torch.Size([256, 768])\n",
      "bert.encoder.layer.6.attention.self.key.bias torch.Size([256])\n",
      "bert.encoder.layer.6.attention.self.value.weight torch.Size([256, 768])\n",
      "bert.encoder.layer.6.attention.self.value.bias torch.Size([256])\n",
      "bert.encoder.layer.6.attention.output.dense.weight torch.Size([768, 256])\n",
      "bert.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.6.intermediate.dense.linear.weight torch.Size([314, 768])\n",
      "bert.encoder.layer.6.intermediate.dense.linear.bias torch.Size([314])\n",
      "bert.encoder.layer.6.output.dense.linear.weight torch.Size([768, 314])\n",
      "bert.encoder.layer.6.output.dense.linear.bias torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.query.weight torch.Size([128, 768])\n",
      "bert.encoder.layer.7.attention.self.query.bias torch.Size([128])\n",
      "bert.encoder.layer.7.attention.self.key.weight torch.Size([128, 768])\n",
      "bert.encoder.layer.7.attention.self.key.bias torch.Size([128])\n",
      "bert.encoder.layer.7.attention.self.value.weight torch.Size([128, 768])\n",
      "bert.encoder.layer.7.attention.self.value.bias torch.Size([128])\n",
      "bert.encoder.layer.7.attention.output.dense.weight torch.Size([768, 128])\n",
      "bert.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.7.intermediate.dense.linear.weight torch.Size([283, 768])\n",
      "bert.encoder.layer.7.intermediate.dense.linear.bias torch.Size([283])\n",
      "bert.encoder.layer.7.output.dense.linear.weight torch.Size([768, 283])\n",
      "bert.encoder.layer.7.output.dense.linear.bias torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.query.weight torch.Size([256, 768])\n",
      "bert.encoder.layer.8.attention.self.query.bias torch.Size([256])\n",
      "bert.encoder.layer.8.attention.self.key.weight torch.Size([256, 768])\n",
      "bert.encoder.layer.8.attention.self.key.bias torch.Size([256])\n",
      "bert.encoder.layer.8.attention.self.value.weight torch.Size([256, 768])\n",
      "bert.encoder.layer.8.attention.self.value.bias torch.Size([256])\n",
      "bert.encoder.layer.8.attention.output.dense.weight torch.Size([768, 256])\n",
      "bert.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.8.intermediate.dense.linear.weight torch.Size([171, 768])\n",
      "bert.encoder.layer.8.intermediate.dense.linear.bias torch.Size([171])\n",
      "bert.encoder.layer.8.output.dense.linear.weight torch.Size([768, 171])\n",
      "bert.encoder.layer.8.output.dense.linear.bias torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.query.weight torch.Size([64, 768])\n",
      "bert.encoder.layer.9.attention.self.query.bias torch.Size([64])\n",
      "bert.encoder.layer.9.attention.self.key.weight torch.Size([64, 768])\n",
      "bert.encoder.layer.9.attention.self.key.bias torch.Size([64])\n",
      "bert.encoder.layer.9.attention.self.value.weight torch.Size([64, 768])\n",
      "bert.encoder.layer.9.attention.self.value.bias torch.Size([64])\n",
      "bert.encoder.layer.9.attention.output.dense.weight torch.Size([768, 64])\n",
      "bert.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.9.intermediate.dense.linear.weight torch.Size([58, 768])\n",
      "bert.encoder.layer.9.intermediate.dense.linear.bias torch.Size([58])\n",
      "bert.encoder.layer.9.output.dense.linear.weight torch.Size([768, 58])\n",
      "bert.encoder.layer.9.output.dense.linear.bias torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.query.weight torch.Size([128, 768])\n",
      "bert.encoder.layer.10.attention.self.query.bias torch.Size([128])\n",
      "bert.encoder.layer.10.attention.self.key.weight torch.Size([128, 768])\n",
      "bert.encoder.layer.10.attention.self.key.bias torch.Size([128])\n",
      "bert.encoder.layer.10.attention.self.value.weight torch.Size([128, 768])\n",
      "bert.encoder.layer.10.attention.self.value.bias torch.Size([128])\n",
      "bert.encoder.layer.10.attention.output.dense.weight torch.Size([768, 128])\n",
      "bert.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.10.intermediate.dense.linear.weight torch.Size([79, 768])\n",
      "bert.encoder.layer.10.intermediate.dense.linear.bias torch.Size([79])\n",
      "bert.encoder.layer.10.output.dense.linear.weight torch.Size([768, 79])\n",
      "bert.encoder.layer.10.output.dense.linear.bias torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.query.weight torch.Size([128, 768])\n",
      "bert.encoder.layer.11.attention.self.query.bias torch.Size([128])\n",
      "bert.encoder.layer.11.attention.self.key.weight torch.Size([128, 768])\n",
      "bert.encoder.layer.11.attention.self.key.bias torch.Size([128])\n",
      "bert.encoder.layer.11.attention.self.value.weight torch.Size([128, 768])\n",
      "bert.encoder.layer.11.attention.self.value.bias torch.Size([128])\n",
      "bert.encoder.layer.11.attention.output.dense.weight torch.Size([768, 128])\n",
      "bert.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
      "bert.encoder.layer.11.intermediate.dense.linear.weight torch.Size([152, 768])\n",
      "bert.encoder.layer.11.intermediate.dense.linear.bias torch.Size([152])\n",
      "bert.encoder.layer.11.output.dense.linear.weight torch.Size([768, 152])\n",
      "bert.encoder.layer.11.output.dense.linear.bias torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "def print_sizes(model):\n",
    "    for k, v in model.named_parameters():\n",
    "        if \"LayerNorm\" not in k and \"encoder\" in k:\n",
    "            print(k, v.shape)\n",
    "\n",
    "print_sizes(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
