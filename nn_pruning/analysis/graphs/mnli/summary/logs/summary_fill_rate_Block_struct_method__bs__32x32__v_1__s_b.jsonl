{"fill_rate": 0.12386067708333348, "matched": 81.67091186958737, "meta": {"annotate": "l=(20, 1.0, 1.0)", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8167091186958737, "eval_loss": 0.6105015277862549}, "eval_metrics_mm": {"eval_accuracy": 0.8164157851912124, "eval_loss": 0.5977670550346375}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl20/checkpoint-100000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 3.706828052520752, "eval_elapsed_time": 5.182821474969387}, "speed_mm": {"cuda_eval_elapsed_time": 3.3266038932800295, "eval_elapsed_time": 4.799467529170215}, "speedup": 2.7241092773734668, "stats": {"layers": {"0": {"linear_attention_nnz": 555008, "linear_attention_total": 2359296, "linear_dense_nnz": 268800, "linear_dense_total": 4718592, "linear_nnz": 823808, "linear_total": 7077888, "nnz": 829295, "total": 7087872}, "1": {"linear_attention_nnz": 592896, "linear_attention_total": 2359296, "linear_dense_nnz": 304128, "linear_dense_total": 4718592, "linear_nnz": 897024, "linear_total": 7077888, "nnz": 902566, "total": 7087872}, "10": {"linear_attention_nnz": 230400, "linear_attention_total": 2359296, "linear_dense_nnz": 70656, "linear_dense_total": 4718592, "linear_nnz": 301056, "linear_total": 7077888, "nnz": 306030, "total": 7087872}, "11": {"linear_attention_nnz": 133120, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 156160, "linear_total": 7077888, "nnz": 161199, "total": 7087872}, "2": {"linear_attention_nnz": 582656, "linear_attention_total": 2359296, "linear_dense_nnz": 459264, "linear_dense_total": 4718592, "linear_nnz": 1041920, "linear_total": 7077888, "nnz": 1047499, "total": 7087872}, "3": {"linear_attention_nnz": 742400, "linear_attention_total": 2359296, "linear_dense_nnz": 614400, "linear_dense_total": 4718592, "linear_nnz": 1356800, "linear_total": 7077888, "nnz": 1362736, "total": 7087872}, "4": {"linear_attention_nnz": 730112, "linear_attention_total": 2359296, "linear_dense_nnz": 602112, "linear_dense_total": 4718592, "linear_nnz": 1332224, "linear_total": 7077888, "nnz": 1338120, "total": 7087872}, "5": {"linear_attention_nnz": 840704, "linear_attention_total": 2359296, "linear_dense_nnz": 489984, "linear_dense_total": 4718592, "linear_nnz": 1330688, "linear_total": 7077888, "nnz": 1336799, "total": 7087872}, "6": {"linear_attention_nnz": 523264, "linear_attention_total": 2359296, "linear_dense_nnz": 436224, "linear_dense_total": 4718592, "linear_nnz": 959488, "linear_total": 7077888, "nnz": 965116, "total": 7087872}, "7": {"linear_attention_nnz": 568320, "linear_attention_total": 2359296, "linear_dense_nnz": 453120, "linear_dense_total": 4718592, "linear_nnz": 1021440, "linear_total": 7077888, "nnz": 1027079, "total": 7087872}, "8": {"linear_attention_nnz": 483328, "linear_attention_total": 2359296, "linear_dense_nnz": 327168, "linear_dense_total": 4718592, "linear_nnz": 810496, "linear_total": 7077888, "nnz": 816085, "total": 7087872}, "9": {"linear_attention_nnz": 376832, "linear_attention_total": 2359296, "linear_dense_nnz": 112128, "linear_dense_total": 4718592, "linear_nnz": 488960, "linear_total": 7077888, "nnz": 494185, "total": 7087872}}, "linear_nnz": 10520064, "linear_sparsity": 87.61393229166666, "linear_total": 84934656, "nnz": 35016792, "pruned_heads": {"0": [0, 1, 2, 4, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [0, 1, 3, 4, 5, 7, 8, 11], "3": [1, 2, 3, 4, 6, 7, 8], "4": [0, 1, 2, 4, 8, 10, 11], "5": [1, 2, 5, 6, 11], "6": [2, 3, 4, 6, 7, 10, 11], "7": [2, 3, 4, 5, 6, 7, 11], "8": [0, 3, 5, 6, 7, 8, 10], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 68.01668092941007}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.12386067708333348, "matched": 81.67091186958737, "mismatched": 81.64157851912124, "speedup": 2.7241092773734668}}
{"fill_rate": 0.11340181327160492, "matched": 81.37544574630667, "meta": {"annotate": "l=(20, 1.0, 1.0)", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8137544574630667, "eval_loss": 0.6326338052749634}, "eval_metrics_mm": {"eval_accuracy": 0.8127542717656632, "eval_loss": 0.6192973852157593}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl20/checkpoint-130000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 3.2572239360809325, "eval_elapsed_time": 4.710650565102696}, "speed_mm": {"cuda_eval_elapsed_time": 3.254903652191162, "eval_elapsed_time": 4.693939131684601}, "speedup": 3.1001260231587278, "stats": {"layers": {"0": {"linear_attention_nnz": 495616, "linear_attention_total": 2359296, "linear_dense_nnz": 224256, "linear_dense_total": 4718592, "linear_nnz": 719872, "linear_total": 7077888, "nnz": 725266, "total": 7087872}, "1": {"linear_attention_nnz": 540672, "linear_attention_total": 2359296, "linear_dense_nnz": 258048, "linear_dense_total": 4718592, "linear_nnz": 798720, "linear_total": 7077888, "nnz": 804168, "total": 7087872}, "10": {"linear_attention_nnz": 223232, "linear_attention_total": 2359296, "linear_dense_nnz": 64512, "linear_dense_total": 4718592, "linear_nnz": 287744, "linear_total": 7077888, "nnz": 292714, "total": 7087872}, "11": {"linear_attention_nnz": 118784, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 141824, "linear_total": 7077888, "nnz": 146831, "total": 7087872}, "2": {"linear_attention_nnz": 570368, "linear_attention_total": 2359296, "linear_dense_nnz": 413184, "linear_dense_total": 4718592, "linear_nnz": 983552, "linear_total": 7077888, "nnz": 989101, "total": 7087872}, "3": {"linear_attention_nnz": 688128, "linear_attention_total": 2359296, "linear_dense_nnz": 571392, "linear_dense_total": 4718592, "linear_nnz": 1259520, "linear_total": 7077888, "nnz": 1265364, "total": 7087872}, "4": {"linear_attention_nnz": 663552, "linear_attention_total": 2359296, "linear_dense_nnz": 556032, "linear_dense_total": 4718592, "linear_nnz": 1219584, "linear_total": 7077888, "nnz": 1225418, "total": 7087872}, "5": {"linear_attention_nnz": 753664, "linear_attention_total": 2359296, "linear_dense_nnz": 450048, "linear_dense_total": 4718592, "linear_nnz": 1203712, "linear_total": 7077888, "nnz": 1209765, "total": 7087872}, "6": {"linear_attention_nnz": 525312, "linear_attention_total": 2359296, "linear_dense_nnz": 405504, "linear_dense_total": 4718592, "linear_nnz": 930816, "linear_total": 7077888, "nnz": 936424, "total": 7087872}, "7": {"linear_attention_nnz": 524288, "linear_attention_total": 2359296, "linear_dense_nnz": 411648, "linear_dense_total": 4718592, "linear_nnz": 935936, "linear_total": 7077888, "nnz": 941548, "total": 7087872}, "8": {"linear_attention_nnz": 355328, "linear_attention_total": 2359296, "linear_dense_nnz": 307200, "linear_dense_total": 4718592, "linear_nnz": 662528, "linear_total": 7077888, "nnz": 667976, "total": 7087872}, "9": {"linear_attention_nnz": 385024, "linear_attention_total": 2359296, "linear_dense_nnz": 102912, "linear_dense_total": 4718592, "linear_nnz": 487936, "linear_total": 7077888, "nnz": 493059, "total": 7087872}}, "linear_nnz": 9631744, "linear_sparsity": 88.6598186728395, "linear_total": 84934656, "nnz": 34127717, "pruned_heads": {"0": [0, 1, 2, 4, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [0, 1, 3, 4, 5, 7, 8, 11], "3": [1, 2, 3, 4, 6, 7, 8], "4": [0, 1, 2, 4, 8, 10, 11], "5": [1, 2, 5, 6, 11], "6": [2, 3, 4, 6, 7, 10, 11], "7": [2, 3, 4, 5, 6, 7, 11], "8": [0, 2, 3, 5, 6, 7, 8, 10], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 68.8287361685846}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.11340181327160492, "matched": 81.37544574630667, "mismatched": 81.27542717656631, "speedup": 3.1001260231587278}}
{"fill_rate": 0.1114064911265431, "matched": 81.29393785022924, "meta": {"annotate": "l=(20, 1.0, 1.0)", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8129393785022924, "eval_loss": 0.6277854442596436}, "eval_metrics_mm": {"eval_accuracy": 0.8157038242473555, "eval_loss": 0.6225855350494385}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl20/checkpoint-140000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 3.254990692138672, "eval_elapsed_time": 4.710992993786931}, "speed_mm": {"cuda_eval_elapsed_time": 3.2467606430053713, "eval_elapsed_time": 4.675681728869677}, "speedup": 3.1022530146976544, "stats": {"layers": {"0": {"linear_attention_nnz": 482304, "linear_attention_total": 2359296, "linear_dense_nnz": 221184, "linear_dense_total": 4718592, "linear_nnz": 703488, "linear_total": 7077888, "nnz": 708848, "total": 7087872}, "1": {"linear_attention_nnz": 527360, "linear_attention_total": 2359296, "linear_dense_nnz": 256512, "linear_dense_total": 4718592, "linear_nnz": 783872, "linear_total": 7077888, "nnz": 789319, "total": 7087872}, "10": {"linear_attention_nnz": 214016, "linear_attention_total": 2359296, "linear_dense_nnz": 64512, "linear_dense_total": 4718592, "linear_nnz": 278528, "linear_total": 7077888, "nnz": 283530, "total": 7087872}, "11": {"linear_attention_nnz": 117760, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 140800, "linear_total": 7077888, "nnz": 145807, "total": 7087872}, "2": {"linear_attention_nnz": 563200, "linear_attention_total": 2359296, "linear_dense_nnz": 411648, "linear_dense_total": 4718592, "linear_nnz": 974848, "linear_total": 7077888, "nnz": 980396, "total": 7087872}, "3": {"linear_attention_nnz": 677888, "linear_attention_total": 2359296, "linear_dense_nnz": 569856, "linear_dense_total": 4718592, "linear_nnz": 1247744, "linear_total": 7077888, "nnz": 1253587, "total": 7087872}, "4": {"linear_attention_nnz": 664576, "linear_attention_total": 2359296, "linear_dense_nnz": 552960, "linear_dense_total": 4718592, "linear_nnz": 1217536, "linear_total": 7077888, "nnz": 1223368, "total": 7087872}, "5": {"linear_attention_nnz": 712704, "linear_attention_total": 2359296, "linear_dense_nnz": 445440, "linear_dense_total": 4718592, "linear_nnz": 1158144, "linear_total": 7077888, "nnz": 1164194, "total": 7087872}, "6": {"linear_attention_nnz": 510976, "linear_attention_total": 2359296, "linear_dense_nnz": 405504, "linear_dense_total": 4718592, "linear_nnz": 916480, "linear_total": 7077888, "nnz": 922088, "total": 7087872}, "7": {"linear_attention_nnz": 504832, "linear_attention_total": 2359296, "linear_dense_nnz": 410112, "linear_dense_total": 4718592, "linear_nnz": 914944, "linear_total": 7077888, "nnz": 920555, "total": 7087872}, "8": {"linear_attention_nnz": 344064, "linear_attention_total": 2359296, "linear_dense_nnz": 304128, "linear_dense_total": 4718592, "linear_nnz": 648192, "linear_total": 7077888, "nnz": 653638, "total": 7087872}, "9": {"linear_attention_nnz": 374784, "linear_attention_total": 2359296, "linear_dense_nnz": 102912, "linear_dense_total": 4718592, "linear_nnz": 477696, "linear_total": 7077888, "nnz": 482851, "total": 7087872}}, "linear_nnz": 9462272, "linear_sparsity": 88.85935088734568, "linear_total": 84934656, "nnz": 33958264, "pruned_heads": {"0": [0, 1, 2, 4, 6, 7, 8, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [0, 1, 3, 4, 5, 7, 8, 11], "3": [1, 2, 3, 4, 6, 7, 8], "4": [0, 1, 2, 4, 8, 10, 11], "5": [1, 2, 5, 6, 11], "6": [2, 3, 4, 6, 7, 10, 11], "7": [2, 3, 4, 5, 6, 7, 11], "8": [0, 2, 3, 5, 6, 7, 8, 10], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 68.98350960889485}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.1114064911265431, "matched": 81.29393785022924, "mismatched": 81.57038242473556, "speedup": 3.1022530146976544}}
{"fill_rate": 0.11082175925925919, "matched": 81.07997962302598, "meta": {"annotate": "l=(20, 1.0, 1.0)", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8107997962302598, "eval_loss": 0.6324005126953125}, "eval_metrics_mm": {"eval_accuracy": 0.8147884458909682, "eval_loss": 0.6208154559135437}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl20/checkpoint-145000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 3.251750114440918, "eval_elapsed_time": 4.698142671957612}, "speed_mm": {"cuda_eval_elapsed_time": 3.251491035461426, "eval_elapsed_time": 4.703871133737266}, "speedup": 3.1053446089402668, "stats": {"layers": {"0": {"linear_attention_nnz": 479232, "linear_attention_total": 2359296, "linear_dense_nnz": 221184, "linear_dense_total": 4718592, "linear_nnz": 700416, "linear_total": 7077888, "nnz": 705776, "total": 7087872}, "1": {"linear_attention_nnz": 503808, "linear_attention_total": 2359296, "linear_dense_nnz": 254976, "linear_dense_total": 4718592, "linear_nnz": 758784, "linear_total": 7077888, "nnz": 764230, "total": 7087872}, "10": {"linear_attention_nnz": 200704, "linear_attention_total": 2359296, "linear_dense_nnz": 64512, "linear_dense_total": 4718592, "linear_nnz": 265216, "linear_total": 7077888, "nnz": 270218, "total": 7087872}, "11": {"linear_attention_nnz": 119808, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 142848, "linear_total": 7077888, "nnz": 147855, "total": 7087872}, "2": {"linear_attention_nnz": 562176, "linear_attention_total": 2359296, "linear_dense_nnz": 411648, "linear_dense_total": 4718592, "linear_nnz": 973824, "linear_total": 7077888, "nnz": 979372, "total": 7087872}, "3": {"linear_attention_nnz": 679936, "linear_attention_total": 2359296, "linear_dense_nnz": 569856, "linear_dense_total": 4718592, "linear_nnz": 1249792, "linear_total": 7077888, "nnz": 1255635, "total": 7087872}, "4": {"linear_attention_nnz": 664576, "linear_attention_total": 2359296, "linear_dense_nnz": 552960, "linear_dense_total": 4718592, "linear_nnz": 1217536, "linear_total": 7077888, "nnz": 1223368, "total": 7087872}, "5": {"linear_attention_nnz": 701440, "linear_attention_total": 2359296, "linear_dense_nnz": 445440, "linear_dense_total": 4718592, "linear_nnz": 1146880, "linear_total": 7077888, "nnz": 1152866, "total": 7087872}, "6": {"linear_attention_nnz": 531456, "linear_attention_total": 2359296, "linear_dense_nnz": 405504, "linear_dense_total": 4718592, "linear_nnz": 936960, "linear_total": 7077888, "nnz": 942568, "total": 7087872}, "7": {"linear_attention_nnz": 508928, "linear_attention_total": 2359296, "linear_dense_nnz": 410112, "linear_dense_total": 4718592, "linear_nnz": 919040, "linear_total": 7077888, "nnz": 924651, "total": 7087872}, "8": {"linear_attention_nnz": 326656, "linear_attention_total": 2359296, "linear_dense_nnz": 304128, "linear_dense_total": 4718592, "linear_nnz": 630784, "linear_total": 7077888, "nnz": 636198, "total": 7087872}, "9": {"linear_attention_nnz": 367616, "linear_attention_total": 2359296, "linear_dense_nnz": 102912, "linear_dense_total": 4718592, "linear_nnz": 470528, "linear_total": 7077888, "nnz": 475651, "total": 7087872}}, "linear_nnz": 9412608, "linear_sparsity": 88.91782407407408, "linear_total": 84934656, "nnz": 33908471, "pruned_heads": {"0": [0, 1, 2, 4, 6, 7, 8, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [0, 1, 3, 4, 5, 7, 8, 11], "3": [1, 2, 3, 4, 6, 7, 8], "4": [0, 1, 2, 4, 8, 10, 11], "5": [1, 2, 5, 6, 11], "6": [2, 3, 4, 6, 7, 10, 11], "7": [2, 3, 4, 5, 6, 7, 11], "8": [0, 2, 3, 5, 6, 7, 8, 10], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 69.02898908646897}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.11082175925925919, "matched": 81.07997962302598, "mismatched": 81.47884458909682, "speedup": 3.1053446089402668}}
{"fill_rate": 0.06458574459876543, "matched": 80.539989811513, "meta": {"annotate": "l=(40, 1.0, 1.0)", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8053998981151299, "eval_loss": 0.6555120944976807}, "eval_metrics_mm": {"eval_accuracy": 0.8049227013832384, "eval_loss": 0.6468992829322815}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl40/checkpoint-140000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 40}, "speed": {"cuda_eval_elapsed_time": 3.150103384017944, "eval_elapsed_time": 4.655201748013496}, "speed_mm": {"cuda_eval_elapsed_time": 2.7430186252593995, "eval_elapsed_time": 4.212751531042159}, "speedup": 3.205547074655147, "stats": {"layers": {"0": {"linear_attention_nnz": 362496, "linear_attention_total": 2359296, "linear_dense_nnz": 93696, "linear_dense_total": 4718592, "linear_nnz": 456192, "linear_total": 7077888, "nnz": 461309, "total": 7087872}, "1": {"linear_attention_nnz": 310272, "linear_attention_total": 2359296, "linear_dense_nnz": 98304, "linear_dense_total": 4718592, "linear_nnz": 408576, "linear_total": 7077888, "nnz": 413600, "total": 7087872}, "10": {"linear_attention_nnz": 116736, "linear_attention_total": 2359296, "linear_dense_nnz": 46080, "linear_dense_total": 4718592, "linear_nnz": 162816, "linear_total": 7077888, "nnz": 167390, "total": 7087872}, "11": {"linear_attention_nnz": 86016, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 109056, "linear_total": 7077888, "nnz": 113871, "total": 7087872}, "2": {"linear_attention_nnz": 515072, "linear_attention_total": 2359296, "linear_dense_nnz": 192000, "linear_dense_total": 4718592, "linear_nnz": 707072, "linear_total": 7077888, "nnz": 712413, "total": 7087872}, "3": {"linear_attention_nnz": 431104, "linear_attention_total": 2359296, "linear_dense_nnz": 285696, "linear_dense_total": 4718592, "linear_nnz": 716800, "linear_total": 7077888, "nnz": 722202, "total": 7087872}, "4": {"linear_attention_nnz": 323584, "linear_attention_total": 2359296, "linear_dense_nnz": 279552, "linear_dense_total": 4718592, "linear_nnz": 603136, "linear_total": 7077888, "nnz": 608406, "total": 7087872}, "5": {"linear_attention_nnz": 361472, "linear_attention_total": 2359296, "linear_dense_nnz": 225792, "linear_dense_total": 4718592, "linear_nnz": 587264, "linear_total": 7077888, "nnz": 592627, "total": 7087872}, "6": {"linear_attention_nnz": 272384, "linear_attention_total": 2359296, "linear_dense_nnz": 213504, "linear_dense_total": 4718592, "linear_nnz": 485888, "linear_total": 7077888, "nnz": 491019, "total": 7087872}, "7": {"linear_attention_nnz": 269312, "linear_attention_total": 2359296, "linear_dense_nnz": 254976, "linear_dense_total": 4718592, "linear_nnz": 524288, "linear_total": 7077888, "nnz": 529510, "total": 7087872}, "8": {"linear_attention_nnz": 183296, "linear_attention_total": 2359296, "linear_dense_nnz": 199680, "linear_dense_total": 4718592, "linear_nnz": 382976, "linear_total": 7077888, "nnz": 387970, "total": 7087872}, "9": {"linear_attention_nnz": 272384, "linear_attention_total": 2359296, "linear_dense_nnz": 69120, "linear_dense_total": 4718592, "linear_nnz": 341504, "linear_total": 7077888, "nnz": 346445, "total": 7087872}}, "linear_nnz": 5485568, "linear_sparsity": 93.54142554012346, "linear_total": 84934656, "nnz": 29976845, "pruned_heads": {"0": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9], "10": [0, 1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [1, 3, 4, 5, 7, 8, 9, 11], "3": [1, 2, 3, 4, 6, 7, 8, 10], "4": [0, 1, 2, 4, 6, 7, 8, 10, 11], "5": [1, 2, 4, 5, 6, 9, 11], "6": [1, 2, 3, 4, 6, 7, 9, 10, 11], "7": [2, 3, 4, 5, 6, 7, 9, 11], "8": [0, 2, 3, 5, 6, 7, 8, 10, 11], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 72.62002189222191}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.06458574459876543, "matched": 80.539989811513, "mismatched": 80.49227013832385, "speedup": 3.205547074655147}}
{"fill_rate": 0.06432050540123457, "matched": 79.97962302598064, "meta": {"annotate": "l=(40, 1.0, 1.0)", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.7997962302598064, "eval_loss": 0.6668020486831665}, "eval_metrics_mm": {"eval_accuracy": 0.8050244100895037, "eval_loss": 0.6475551724433899}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl40/checkpoint-145000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 40}, "speed": {"cuda_eval_elapsed_time": 2.760984354019165, "eval_elapsed_time": 4.243257373571396}, "speed_mm": {"cuda_eval_elapsed_time": 2.747091209411621, "eval_elapsed_time": 4.217128338292241}, "speedup": 3.657320503392431, "stats": {"layers": {"0": {"linear_attention_nnz": 362496, "linear_attention_total": 2359296, "linear_dense_nnz": 93696, "linear_dense_total": 4718592, "linear_nnz": 456192, "linear_total": 7077888, "nnz": 461309, "total": 7087872}, "1": {"linear_attention_nnz": 294912, "linear_attention_total": 2359296, "linear_dense_nnz": 98304, "linear_dense_total": 4718592, "linear_nnz": 393216, "linear_total": 7077888, "nnz": 398240, "total": 7087872}, "10": {"linear_attention_nnz": 113664, "linear_attention_total": 2359296, "linear_dense_nnz": 46080, "linear_dense_total": 4718592, "linear_nnz": 159744, "linear_total": 7077888, "nnz": 164286, "total": 7087872}, "11": {"linear_attention_nnz": 81920, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 104960, "linear_total": 7077888, "nnz": 109743, "total": 7087872}, "2": {"linear_attention_nnz": 503808, "linear_attention_total": 2359296, "linear_dense_nnz": 192000, "linear_dense_total": 4718592, "linear_nnz": 695808, "linear_total": 7077888, "nnz": 701149, "total": 7087872}, "3": {"linear_attention_nnz": 430080, "linear_attention_total": 2359296, "linear_dense_nnz": 285696, "linear_dense_total": 4718592, "linear_nnz": 715776, "linear_total": 7077888, "nnz": 721178, "total": 7087872}, "4": {"linear_attention_nnz": 321536, "linear_attention_total": 2359296, "linear_dense_nnz": 279552, "linear_dense_total": 4718592, "linear_nnz": 601088, "linear_total": 7077888, "nnz": 606294, "total": 7087872}, "5": {"linear_attention_nnz": 374784, "linear_attention_total": 2359296, "linear_dense_nnz": 225792, "linear_dense_total": 4718592, "linear_nnz": 600576, "linear_total": 7077888, "nnz": 605939, "total": 7087872}, "6": {"linear_attention_nnz": 262144, "linear_attention_total": 2359296, "linear_dense_nnz": 213504, "linear_dense_total": 4718592, "linear_nnz": 475648, "linear_total": 7077888, "nnz": 480779, "total": 7087872}, "7": {"linear_attention_nnz": 266240, "linear_attention_total": 2359296, "linear_dense_nnz": 254976, "linear_dense_total": 4718592, "linear_nnz": 521216, "linear_total": 7077888, "nnz": 526406, "total": 7087872}, "8": {"linear_attention_nnz": 186368, "linear_attention_total": 2359296, "linear_dense_nnz": 199680, "linear_dense_total": 4718592, "linear_nnz": 386048, "linear_total": 7077888, "nnz": 391042, "total": 7087872}, "9": {"linear_attention_nnz": 283648, "linear_attention_total": 2359296, "linear_dense_nnz": 69120, "linear_dense_total": 4718592, "linear_nnz": 352768, "linear_total": 7077888, "nnz": 357677, "total": 7087872}}, "linear_nnz": 5463040, "linear_sparsity": 93.56794945987654, "linear_total": 84934656, "nnz": 29954125, "pruned_heads": {"0": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9], "10": [0, 1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [1, 3, 4, 5, 7, 8, 9, 11], "3": [1, 2, 3, 4, 6, 7, 8, 10], "4": [0, 1, 2, 4, 6, 7, 8, 10, 11], "5": [1, 2, 4, 5, 6, 9, 11], "6": [1, 2, 3, 4, 6, 7, 9, 10, 11], "7": [2, 3, 4, 5, 6, 7, 9, 11], "8": [0, 2, 3, 5, 6, 7, 8, 10, 11], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 72.64077367922982}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.06432050540123457, "matched": 79.97962302598064, "mismatched": 80.50244100895037, "speedup": 3.657320503392431}}
