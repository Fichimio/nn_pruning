{"speedup": 1.0253716557683228, "f1": 88.66263407974378, "meta": {"annotate": "", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 81.40018921475875, "f1": 88.66263407974378}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_abr1_abc1_it0_fw10_r-l1_rfl25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_pruning_method": "sigmoied_threshold", "dense_block_cols": 1, "dense_block_rows": 1, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 25}, "speed": {"cuda_eval_elapsed_time": 37.63941863250732, "eval_elapsed_time": 44.979358388110995}, "speedup": 1.0253716557683228, "stats": {"layers": {"0": {"linear_attention_nnz": 158912, "linear_attention_total": 2359296, "linear_dense_nnz": 1993831, "linear_dense_total": 4718592, "linear_nnz": 2152743, "linear_total": 7077888, "nnz": 768, "total": 768}, "1": {"linear_attention_nnz": 234395, "linear_attention_total": 2359296, "linear_dense_nnz": 2030737, "linear_dense_total": 4718592, "linear_nnz": 2265132, "linear_total": 7077888, "nnz": 768, "total": 768}, "10": {"linear_attention_nnz": 134277, "linear_attention_total": 2359296, "linear_dense_nnz": 440264, "linear_dense_total": 4718592, "linear_nnz": 574541, "linear_total": 7077888, "nnz": 768, "total": 768}, "11": {"linear_attention_nnz": 63309, "linear_attention_total": 2359296, "linear_dense_nnz": 269756, "linear_dense_total": 4718592, "linear_nnz": 333065, "linear_total": 7077888, "nnz": 768, "total": 768}, "2": {"linear_attention_nnz": 301048, "linear_attention_total": 2359296, "linear_dense_nnz": 2114464, "linear_dense_total": 4718592, "linear_nnz": 2415512, "linear_total": 7077888, "nnz": 768, "total": 768}, "3": {"linear_attention_nnz": 358791, "linear_attention_total": 2359296, "linear_dense_nnz": 2106776, "linear_dense_total": 4718592, "linear_nnz": 2465567, "linear_total": 7077888, "nnz": 768, "total": 768}, "4": {"linear_attention_nnz": 398673, "linear_attention_total": 2359296, "linear_dense_nnz": 2058594, "linear_dense_total": 4718592, "linear_nnz": 2457267, "linear_total": 7077888, "nnz": 768, "total": 768}, "5": {"linear_attention_nnz": 367333, "linear_attention_total": 2359296, "linear_dense_nnz": 2043244, "linear_dense_total": 4718592, "linear_nnz": 2410577, "linear_total": 7077888, "nnz": 768, "total": 768}, "6": {"linear_attention_nnz": 344288, "linear_attention_total": 2359296, "linear_dense_nnz": 1862492, "linear_dense_total": 4718592, "linear_nnz": 2206780, "linear_total": 7077888, "nnz": 768, "total": 768}, "7": {"linear_attention_nnz": 304514, "linear_attention_total": 2359296, "linear_dense_nnz": 1514517, "linear_dense_total": 4718592, "linear_nnz": 1819031, "linear_total": 7077888, "nnz": 768, "total": 768}, "8": {"linear_attention_nnz": 265513, "linear_attention_total": 2359296, "linear_dense_nnz": 1099308, "linear_dense_total": 4718592, "linear_nnz": 1364821, "linear_total": 7077888, "nnz": 768, "total": 768}, "9": {"linear_attention_nnz": 201714, "linear_attention_total": 2359296, "linear_dense_nnz": 627276, "linear_dense_total": 4718592, "linear_nnz": 828990, "linear_total": 7077888, "nnz": 768, "total": 768}, "null": {"nnz": 2, "total": 2}}, "linear_nnz": 21294026, "linear_sparsity": 74.92893124804085, "linear_total": 84934656, "nnz": 45252556, "total": 108893186, "total_sparsity": 58.4431701722824}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/squad_test3", "save_steps": 5000, "save_total_limit": 5, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 88.66263407974378, "fill_rate": 0.25071068751959147, "speedup": 1.0253716557683228}}
{"speedup": 1.0930418633843273, "f1": 88.08154392563726, "meta": {"annotate": "", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.22705771050141, "f1": 88.08154392563726}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_abr1_abc1_it0_fw10_r-l1_rfl50_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-95000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_pruning_method": "sigmoied_threshold", "dense_block_cols": 1, "dense_block_rows": 1, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 50}, "speed": {"cuda_eval_elapsed_time": 35.30916271209717, "eval_elapsed_time": 42.719326278194785}, "speedup": 1.0930418633843273, "stats": {"layers": {"0": {"linear_attention_nnz": 87221, "linear_attention_total": 2359296, "linear_dense_nnz": 1434572, "linear_dense_total": 4718592, "linear_nnz": 1521793, "linear_total": 7077888, "nnz": 768, "total": 768}, "1": {"linear_attention_nnz": 157517, "linear_attention_total": 2359296, "linear_dense_nnz": 1480327, "linear_dense_total": 4718592, "linear_nnz": 1637844, "linear_total": 7077888, "nnz": 768, "total": 768}, "10": {"linear_attention_nnz": 75446, "linear_attention_total": 2359296, "linear_dense_nnz": 204546, "linear_dense_total": 4718592, "linear_nnz": 279992, "linear_total": 7077888, "nnz": 768, "total": 768}, "11": {"linear_attention_nnz": 38439, "linear_attention_total": 2359296, "linear_dense_nnz": 144390, "linear_dense_total": 4718592, "linear_nnz": 182829, "linear_total": 7077888, "nnz": 768, "total": 768}, "2": {"linear_attention_nnz": 188172, "linear_attention_total": 2359296, "linear_dense_nnz": 1535574, "linear_dense_total": 4718592, "linear_nnz": 1723746, "linear_total": 7077888, "nnz": 768, "total": 768}, "3": {"linear_attention_nnz": 230341, "linear_attention_total": 2359296, "linear_dense_nnz": 1512620, "linear_dense_total": 4718592, "linear_nnz": 1742961, "linear_total": 7077888, "nnz": 768, "total": 768}, "4": {"linear_attention_nnz": 240387, "linear_attention_total": 2359296, "linear_dense_nnz": 1447041, "linear_dense_total": 4718592, "linear_nnz": 1687428, "linear_total": 7077888, "nnz": 768, "total": 768}, "5": {"linear_attention_nnz": 195780, "linear_attention_total": 2359296, "linear_dense_nnz": 1427597, "linear_dense_total": 4718592, "linear_nnz": 1623377, "linear_total": 7077888, "nnz": 768, "total": 768}, "6": {"linear_attention_nnz": 184963, "linear_attention_total": 2359296, "linear_dense_nnz": 1245019, "linear_dense_total": 4718592, "linear_nnz": 1429982, "linear_total": 7077888, "nnz": 768, "total": 768}, "7": {"linear_attention_nnz": 172954, "linear_attention_total": 2359296, "linear_dense_nnz": 957245, "linear_dense_total": 4718592, "linear_nnz": 1130199, "linear_total": 7077888, "nnz": 768, "total": 768}, "8": {"linear_attention_nnz": 138133, "linear_attention_total": 2359296, "linear_dense_nnz": 635763, "linear_dense_total": 4718592, "linear_nnz": 773896, "linear_total": 7077888, "nnz": 768, "total": 768}, "9": {"linear_attention_nnz": 112972, "linear_attention_total": 2359296, "linear_dense_nnz": 304891, "linear_dense_total": 4718592, "linear_nnz": 417863, "linear_total": 7077888, "nnz": 768, "total": 768}, "null": {"nnz": 2, "total": 2}}, "linear_nnz": 14151910, "linear_sparsity": 83.3378850677867, "linear_total": 84934656, "nnz": 38110440, "total": 108893186, "total_sparsity": 65.00199746198996}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/squad_test3", "save_steps": 5000, "save_total_limit": 5, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 88.08154392563726, "fill_rate": 0.166621149322133, "speedup": 1.0930418633843273}}
{"speedup": 1.170038217254783, "f1": 87.64967103979136, "meta": {"annotate": "", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.89593188268685, "f1": 87.64967103979136}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_abr1_abc1_it0_fw10_r-l1_rfl75_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-105000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_pruning_method": "sigmoied_threshold", "dense_block_cols": 1, "dense_block_rows": 1, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 75}, "speed": {"cuda_eval_elapsed_time": 32.98558323669434, "eval_elapsed_time": 40.38167083170265}, "speedup": 1.170038217254783, "stats": {"layers": {"0": {"linear_attention_nnz": 56754, "linear_attention_total": 2359296, "linear_dense_nnz": 1054479, "linear_dense_total": 4718592, "linear_nnz": 1111233, "linear_total": 7077888, "nnz": 768, "total": 768}, "1": {"linear_attention_nnz": 116764, "linear_attention_total": 2359296, "linear_dense_nnz": 1106103, "linear_dense_total": 4718592, "linear_nnz": 1222867, "linear_total": 7077888, "nnz": 768, "total": 768}, "10": {"linear_attention_nnz": 50915, "linear_attention_total": 2359296, "linear_dense_nnz": 121878, "linear_dense_total": 4718592, "linear_nnz": 172793, "linear_total": 7077888, "nnz": 768, "total": 768}, "11": {"linear_attention_nnz": 28303, "linear_attention_total": 2359296, "linear_dense_nnz": 94314, "linear_dense_total": 4718592, "linear_nnz": 122617, "linear_total": 7077888, "nnz": 768, "total": 768}, "2": {"linear_attention_nnz": 127558, "linear_attention_total": 2359296, "linear_dense_nnz": 1136881, "linear_dense_total": 4718592, "linear_nnz": 1264439, "linear_total": 7077888, "nnz": 768, "total": 768}, "3": {"linear_attention_nnz": 163709, "linear_attention_total": 2359296, "linear_dense_nnz": 1106395, "linear_dense_total": 4718592, "linear_nnz": 1270104, "linear_total": 7077888, "nnz": 768, "total": 768}, "4": {"linear_attention_nnz": 158018, "linear_attention_total": 2359296, "linear_dense_nnz": 1044282, "linear_dense_total": 4718592, "linear_nnz": 1202300, "linear_total": 7077888, "nnz": 768, "total": 768}, "5": {"linear_attention_nnz": 125746, "linear_attention_total": 2359296, "linear_dense_nnz": 1010449, "linear_dense_total": 4718592, "linear_nnz": 1136195, "linear_total": 7077888, "nnz": 768, "total": 768}, "6": {"linear_attention_nnz": 110023, "linear_attention_total": 2359296, "linear_dense_nnz": 861094, "linear_dense_total": 4718592, "linear_nnz": 971117, "linear_total": 7077888, "nnz": 768, "total": 768}, "7": {"linear_attention_nnz": 113086, "linear_attention_total": 2359296, "linear_dense_nnz": 632989, "linear_dense_total": 4718592, "linear_nnz": 746075, "linear_total": 7077888, "nnz": 768, "total": 768}, "8": {"linear_attention_nnz": 81879, "linear_attention_total": 2359296, "linear_dense_nnz": 407092, "linear_dense_total": 4718592, "linear_nnz": 488971, "linear_total": 7077888, "nnz": 768, "total": 768}, "9": {"linear_attention_nnz": 77365, "linear_attention_total": 2359296, "linear_dense_nnz": 173330, "linear_dense_total": 4718592, "linear_nnz": 250695, "linear_total": 7077888, "nnz": 768, "total": 768}, "null": {"nnz": 2, "total": 2}}, "linear_nnz": 9959406, "linear_sparsity": 88.27403739646628, "linear_total": 84934656, "nnz": 33917936, "total": 108893186, "total_sparsity": 68.85210429971255}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20, "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/squad_test3", "save_steps": 5000, "save_total_limit": 5, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.64967103979136, "fill_rate": 0.11725962603533713, "speedup": 1.170038217254783}}
{"speedup": 1.2958210124830911, "f1": 86.3547925481507, "meta": {"annotate": "", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.4484389782403, "f1": 86.3547925481507}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_abr1_abc1_it0_fw10_r-l1_rfl150_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_pruning_method": "sigmoied_threshold", "dense_block_cols": 1, "dense_block_rows": 1, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 150}, "speed": {"cuda_eval_elapsed_time": 29.783737594604492, "eval_elapsed_time": 37.12324417894706}, "speedup": 1.2958210124830911, "stats": {"layers": {"0": {"linear_attention_nnz": 30729, "linear_attention_total": 2359296, "linear_dense_nnz": 624455, "linear_dense_total": 4718592, "linear_nnz": 655184, "linear_total": 7077888, "nnz": 768, "total": 768}, "1": {"linear_attention_nnz": 77742, "linear_attention_total": 2359296, "linear_dense_nnz": 655389, "linear_dense_total": 4718592, "linear_nnz": 733131, "linear_total": 7077888, "nnz": 768, "total": 768}, "10": {"linear_attention_nnz": 27892, "linear_attention_total": 2359296, "linear_dense_nnz": 61389, "linear_dense_total": 4718592, "linear_nnz": 89281, "linear_total": 7077888, "nnz": 768, "total": 768}, "11": {"linear_attention_nnz": 20781, "linear_attention_total": 2359296, "linear_dense_nnz": 51322, "linear_dense_total": 4718592, "linear_nnz": 72103, "linear_total": 7077888, "nnz": 768, "total": 768}, "2": {"linear_attention_nnz": 70206, "linear_attention_total": 2359296, "linear_dense_nnz": 660173, "linear_dense_total": 4718592, "linear_nnz": 730379, "linear_total": 7077888, "nnz": 768, "total": 768}, "3": {"linear_attention_nnz": 106339, "linear_attention_total": 2359296, "linear_dense_nnz": 628112, "linear_dense_total": 4718592, "linear_nnz": 734451, "linear_total": 7077888, "nnz": 768, "total": 768}, "4": {"linear_attention_nnz": 81845, "linear_attention_total": 2359296, "linear_dense_nnz": 574018, "linear_dense_total": 4718592, "linear_nnz": 655863, "linear_total": 7077888, "nnz": 768, "total": 768}, "5": {"linear_attention_nnz": 68554, "linear_attention_total": 2359296, "linear_dense_nnz": 537752, "linear_dense_total": 4718592, "linear_nnz": 606306, "linear_total": 7077888, "nnz": 768, "total": 768}, "6": {"linear_attention_nnz": 58217, "linear_attention_total": 2359296, "linear_dense_nnz": 434629, "linear_dense_total": 4718592, "linear_nnz": 492846, "linear_total": 7077888, "nnz": 768, "total": 768}, "7": {"linear_attention_nnz": 65705, "linear_attention_total": 2359296, "linear_dense_nnz": 313684, "linear_dense_total": 4718592, "linear_nnz": 379389, "linear_total": 7077888, "nnz": 768, "total": 768}, "8": {"linear_attention_nnz": 39483, "linear_attention_total": 2359296, "linear_dense_nnz": 203724, "linear_dense_total": 4718592, "linear_nnz": 243207, "linear_total": 7077888, "nnz": 768, "total": 768}, "9": {"linear_attention_nnz": 46007, "linear_attention_total": 2359296, "linear_dense_nnz": 73599, "linear_dense_total": 4718592, "linear_nnz": 119606, "linear_total": 7077888, "nnz": 768, "total": 768}, "null": {"nnz": 2, "total": 2}}, "linear_nnz": 5511746, "linear_sparsity": 93.51060419906804, "linear_total": 84934656, "nnz": 29470276, "total": 108893186, "total_sparsity": 72.93652882926945}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/squad_test3", "save_steps": 5000, "save_total_limit": 5, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.3547925481507, "fill_rate": 0.06489395800931963, "speedup": 1.2958210124830911}}
{"speedup": 1.3926143255719736, "f1": 85.66626983371626, "meta": {"annotate": "", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.39829706717124, "f1": 85.66626983371626}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_abr1_abc1_it0_fw10_r-l1_rfl225_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_pruning_method": "sigmoied_threshold", "dense_block_cols": 1, "dense_block_rows": 1, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 225}, "speed": {"cuda_eval_elapsed_time": 27.713626304626466, "eval_elapsed_time": 35.06419681990519}, "speedup": 1.3926143255719736, "stats": {"layers": {"0": {"linear_attention_nnz": 18728, "linear_attention_total": 2359296, "linear_dense_nnz": 446655, "linear_dense_total": 4718592, "linear_nnz": 465383, "linear_total": 7077888, "nnz": 768, "total": 768}, "1": {"linear_attention_nnz": 63059, "linear_attention_total": 2359296, "linear_dense_nnz": 464338, "linear_dense_total": 4718592, "linear_nnz": 527397, "linear_total": 7077888, "nnz": 768, "total": 768}, "10": {"linear_attention_nnz": 21311, "linear_attention_total": 2359296, "linear_dense_nnz": 43332, "linear_dense_total": 4718592, "linear_nnz": 64643, "linear_total": 7077888, "nnz": 768, "total": 768}, "11": {"linear_attention_nnz": 17233, "linear_attention_total": 2359296, "linear_dense_nnz": 36806, "linear_dense_total": 4718592, "linear_nnz": 54039, "linear_total": 7077888, "nnz": 768, "total": 768}, "2": {"linear_attention_nnz": 53761, "linear_attention_total": 2359296, "linear_dense_nnz": 462731, "linear_dense_total": 4718592, "linear_nnz": 516492, "linear_total": 7077888, "nnz": 768, "total": 768}, "3": {"linear_attention_nnz": 84624, "linear_attention_total": 2359296, "linear_dense_nnz": 430348, "linear_dense_total": 4718592, "linear_nnz": 514972, "linear_total": 7077888, "nnz": 768, "total": 768}, "4": {"linear_attention_nnz": 58345, "linear_attention_total": 2359296, "linear_dense_nnz": 384869, "linear_dense_total": 4718592, "linear_nnz": 443214, "linear_total": 7077888, "nnz": 768, "total": 768}, "5": {"linear_attention_nnz": 50615, "linear_attention_total": 2359296, "linear_dense_nnz": 346306, "linear_dense_total": 4718592, "linear_nnz": 396921, "linear_total": 7077888, "nnz": 768, "total": 768}, "6": {"linear_attention_nnz": 41344, "linear_attention_total": 2359296, "linear_dense_nnz": 277660, "linear_dense_total": 4718592, "linear_nnz": 319004, "linear_total": 7077888, "nnz": 768, "total": 768}, "7": {"linear_attention_nnz": 47420, "linear_attention_total": 2359296, "linear_dense_nnz": 201763, "linear_dense_total": 4718592, "linear_nnz": 249183, "linear_total": 7077888, "nnz": 768, "total": 768}, "8": {"linear_attention_nnz": 27562, "linear_attention_total": 2359296, "linear_dense_nnz": 133500, "linear_dense_total": 4718592, "linear_nnz": 161062, "linear_total": 7077888, "nnz": 768, "total": 768}, "9": {"linear_attention_nnz": 34151, "linear_attention_total": 2359296, "linear_dense_nnz": 47554, "linear_dense_total": 4718592, "linear_nnz": 81705, "linear_total": 7077888, "nnz": 768, "total": 768}, "null": {"nnz": 2, "total": 2}}, "linear_nnz": 3794015, "linear_sparsity": 95.5330189363456, "linear_total": 84934656, "nnz": 27752545, "total": 108893186, "total_sparsity": 74.51397463933142}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/squad_test3", "save_steps": 5000, "save_total_limit": 5, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.66626983371626, "fill_rate": 0.04466981063654396, "speedup": 1.3926143255719736}}
{"speedup": 1.5170581452285046, "f1": 85.40699359564026, "meta": {"annotate": "", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 76.98202459791864, "f1": 85.40699359564026}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_abr1_abc1_it0_fw10_r-l1_rfl300_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_pruning_method": "sigmoied_threshold", "dense_block_cols": 1, "dense_block_rows": 1, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 300}, "speed": {"cuda_eval_elapsed_time": 25.440285942077637, "eval_elapsed_time": 32.748252402991056}, "speedup": 1.5170581452285046, "stats": {"layers": {"0": {"linear_attention_nnz": 13195, "linear_attention_total": 2359296, "linear_dense_nnz": 344662, "linear_dense_total": 4718592, "linear_nnz": 357857, "linear_total": 7077888, "nnz": 768, "total": 768}, "1": {"linear_attention_nnz": 53357, "linear_attention_total": 2359296, "linear_dense_nnz": 352125, "linear_dense_total": 4718592, "linear_nnz": 405482, "linear_total": 7077888, "nnz": 768, "total": 768}, "10": {"linear_attention_nnz": 18747, "linear_attention_total": 2359296, "linear_dense_nnz": 34723, "linear_dense_total": 4718592, "linear_nnz": 53470, "linear_total": 7077888, "nnz": 768, "total": 768}, "11": {"linear_attention_nnz": 15957, "linear_attention_total": 2359296, "linear_dense_nnz": 30412, "linear_dense_total": 4718592, "linear_nnz": 46369, "linear_total": 7077888, "nnz": 768, "total": 768}, "2": {"linear_attention_nnz": 43981, "linear_attention_total": 2359296, "linear_dense_nnz": 351138, "linear_dense_total": 4718592, "linear_nnz": 395119, "linear_total": 7077888, "nnz": 768, "total": 768}, "3": {"linear_attention_nnz": 71058, "linear_attention_total": 2359296, "linear_dense_nnz": 323059, "linear_dense_total": 4718592, "linear_nnz": 394117, "linear_total": 7077888, "nnz": 768, "total": 768}, "4": {"linear_attention_nnz": 47705, "linear_attention_total": 2359296, "linear_dense_nnz": 287668, "linear_dense_total": 4718592, "linear_nnz": 335373, "linear_total": 7077888, "nnz": 768, "total": 768}, "5": {"linear_attention_nnz": 40348, "linear_attention_total": 2359296, "linear_dense_nnz": 252178, "linear_dense_total": 4718592, "linear_nnz": 292526, "linear_total": 7077888, "nnz": 768, "total": 768}, "6": {"linear_attention_nnz": 33002, "linear_attention_total": 2359296, "linear_dense_nnz": 205112, "linear_dense_total": 4718592, "linear_nnz": 238114, "linear_total": 7077888, "nnz": 768, "total": 768}, "7": {"linear_attention_nnz": 38753, "linear_attention_total": 2359296, "linear_dense_nnz": 150138, "linear_dense_total": 4718592, "linear_nnz": 188891, "linear_total": 7077888, "nnz": 768, "total": 768}, "8": {"linear_attention_nnz": 22052, "linear_attention_total": 2359296, "linear_dense_nnz": 101313, "linear_dense_total": 4718592, "linear_nnz": 123365, "linear_total": 7077888, "nnz": 768, "total": 768}, "9": {"linear_attention_nnz": 28498, "linear_attention_total": 2359296, "linear_dense_nnz": 35917, "linear_dense_total": 4718592, "linear_nnz": 64415, "linear_total": 7077888, "nnz": 768, "total": 768}, "null": {"nnz": 2, "total": 2}}, "linear_nnz": 2895098, "linear_sparsity": 96.59138196780358, "linear_total": 84934656, "nnz": 26853628, "total": 108893186, "total_sparsity": 75.33947808267818}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/squad_test3", "save_steps": 5000, "save_total_limit": 5, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.40699359564026, "fill_rate": 0.0340861803219642, "speedup": 1.5170581452285046}}
