{"fill_rate": 0.8222085160818713, "f1": 91.0266636723574, "meta": {"annotate": "", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 7, 8, 10, 12, 13], "11": [0, 1, 2, 4, 5, 8, 10], "12": [2, 3, 5, 6, 7, 8, 10, 13], "13": [10, 2, 3, 12], "14": [1, 2, 3, 4, 8, 11], "15": [0, 5, 6, 7, 11, 12], "16": [3, 6, 8, 10, 13, 15], "17": [0, 2, 11, 15], "18": [2, 3, 5, 9, 11, 12, 13], "19": [0, 2, 3, 4, 9, 10, 11, 13, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15], "23": [1, 2, 4, 5, 6, 7, 9, 10, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14], "6": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 84.63576158940397, "f1": 91.0266636723574}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_10_d0.25_v3_f91.03/checkpoint-55000", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_10_d0.25/checkpoint-210000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 41.85157574462891, "eval_elapsed_time": 49.32021534908563}, "speedup": 0.9221729963255725, "stats": {"layers": {"0": {"linear_attention_nnz": 1572864, "linear_attention_total": 1572864, "linear_dense_nnz": 835584, "linear_dense_total": 8388608, "linear_nnz": 2408448, "linear_total": 9961472, "nnz": 1024, "total": 1024}, "1": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 1275904, "linear_dense_total": 8388608, "linear_nnz": 1800192, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "10": {"linear_attention_nnz": 2621440, "linear_attention_total": 2621440, "linear_dense_nnz": 2410496, "linear_dense_total": 8388608, "linear_nnz": 5031936, "linear_total": 11010048, "nnz": 1024, "total": 1024}, "11": {"linear_attention_nnz": 2359296, "linear_attention_total": 2359296, "linear_dense_nnz": 2510848, "linear_dense_total": 8388608, "linear_nnz": 4870144, "linear_total": 10747904, "nnz": 1024, "total": 1024}, "12": {"linear_attention_nnz": 2097152, "linear_attention_total": 2097152, "linear_dense_nnz": 2660352, "linear_dense_total": 8388608, "linear_nnz": 4757504, "linear_total": 10485760, "nnz": 1024, "total": 1024}, "13": {"linear_attention_nnz": 3145728, "linear_attention_total": 3145728, "linear_dense_nnz": 2605056, "linear_dense_total": 8388608, "linear_nnz": 5750784, "linear_total": 11534336, "nnz": 1024, "total": 1024}, "14": {"linear_attention_nnz": 2621440, "linear_attention_total": 2621440, "linear_dense_nnz": 2299904, "linear_dense_total": 8388608, "linear_nnz": 4921344, "linear_total": 11010048, "nnz": 1024, "total": 1024}, "15": {"linear_attention_nnz": 2621440, "linear_attention_total": 2621440, "linear_dense_nnz": 1699840, "linear_dense_total": 8388608, "linear_nnz": 4321280, "linear_total": 11010048, "nnz": 1024, "total": 1024}, "16": {"linear_attention_nnz": 2621440, "linear_attention_total": 2621440, "linear_dense_nnz": 1402880, "linear_dense_total": 8388608, "linear_nnz": 4024320, "linear_total": 11010048, "nnz": 1024, "total": 1024}, "17": {"linear_attention_nnz": 3145728, "linear_attention_total": 3145728, "linear_dense_nnz": 1097728, "linear_dense_total": 8388608, "linear_nnz": 4243456, "linear_total": 11534336, "nnz": 1024, "total": 1024}, "18": {"linear_attention_nnz": 2359296, "linear_attention_total": 2359296, "linear_dense_nnz": 901120, "linear_dense_total": 8388608, "linear_nnz": 3260416, "linear_total": 10747904, "nnz": 1024, "total": 1024}, "19": {"linear_attention_nnz": 1835008, "linear_attention_total": 1835008, "linear_dense_nnz": 739328, "linear_dense_total": 8388608, "linear_nnz": 2574336, "linear_total": 10223616, "nnz": 1024, "total": 1024}, "2": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 1359872, "linear_dense_total": 8388608, "linear_nnz": 1884160, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "20": {"linear_attention_nnz": 1048576, "linear_attention_total": 1048576, "linear_dense_nnz": 358400, "linear_dense_total": 8388608, "linear_nnz": 1406976, "linear_total": 9437184, "nnz": 1024, "total": 1024}, "21": {"linear_attention_nnz": 1048576, "linear_attention_total": 1048576, "linear_dense_nnz": 194560, "linear_dense_total": 8388608, "linear_nnz": 1243136, "linear_total": 9437184, "nnz": 1024, "total": 1024}, "22": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 180224, "linear_dense_total": 8388608, "linear_nnz": 704512, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "23": {"linear_attention_nnz": 1310720, "linear_attention_total": 1310720, "linear_dense_nnz": 323584, "linear_dense_total": 8388608, "linear_nnz": 1634304, "linear_total": 9699328, "nnz": 1024, "total": 1024}, "3": {"linear_attention_nnz": 1048576, "linear_attention_total": 1048576, "linear_dense_nnz": 1685504, "linear_dense_total": 8388608, "linear_nnz": 2734080, "linear_total": 9437184, "nnz": 1024, "total": 1024}, "4": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 1767424, "linear_dense_total": 8388608, "linear_nnz": 2291712, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "5": {"linear_attention_nnz": 786432, "linear_attention_total": 786432, "linear_dense_nnz": 1873920, "linear_dense_total": 8388608, "linear_nnz": 2660352, "linear_total": 9175040, "nnz": 1024, "total": 1024}, "6": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 2054144, "linear_dense_total": 8388608, "linear_nnz": 2578432, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "7": {"linear_attention_nnz": 1048576, "linear_attention_total": 1048576, "linear_dense_nnz": 1773568, "linear_dense_total": 8388608, "linear_nnz": 2822144, "linear_total": 9437184, "nnz": 1024, "total": 1024}, "8": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 1968128, "linear_dense_total": 8388608, "linear_nnz": 2492416, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "9": {"linear_attention_nnz": 1310720, "linear_attention_total": 1310720, "linear_dense_nnz": 1986560, "linear_dense_total": 8388608, "linear_nnz": 3297280, "linear_total": 9699328, "nnz": 1024, "total": 1024}, "null": {"nnz": 2, "total": 2}}, "linear_nnz": 73713664, "linear_sparsity": 69.16718064692982, "linear_total": 239075328, "nnz": 105691291, "total": 271133698, "total_sparsity": 61.01875503501597}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_10_d0.25", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 10, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_10_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_10_d0.25", "save_steps": 2500, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 91.0266636723574, "fill_rate": 0.8222085160818713, "speedup": 0.9221729963255725}}
{"fill_rate": 0.5930300575953924, "f1": 90.16320537561052, "meta": {"annotate": "", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [2, 3, 4, 7, 8, 9, 10, 13, 14, 15], "1": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [7, 8, 10, 12, 13, 14], "11": [0, 2, 4, 5, 8, 10], "12": [10, 3, 13, 6], "13": [2, 10, 4, 12], "14": [2, 3, 4, 8, 11], "15": [0, 5, 6, 7, 11, 12], "16": [3, 6, 8, 13, 15], "17": [0, 2, 4, 11, 15], "18": [2, 3, 5, 11, 13], "19": [0, 2, 3, 4, 9, 10, 11, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14], "23": [1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 10, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 13, 14], "8": [0, 1, 2, 3, 4, 5, 6, 8, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 8, 12, 13, 15]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 83.74645222327341, "f1": 90.16320537561052}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_10/checkpoint-47500", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_10/checkpoint-215000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 37.53850735473633, "eval_elapsed_time": 44.58338421070948}, "speedup": 1.0281280670181348, "stats": {"layers": {"0": {"linear_attention_nnz": 1572864, "linear_attention_total": 1572864, "linear_dense_nnz": 192512, "linear_dense_total": 8388608, "linear_nnz": 1765376, "linear_total": 9961472, "nnz": 1024, "total": 1024}, "1": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 270336, "linear_dense_total": 8388608, "linear_nnz": 794624, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "10": {"linear_attention_nnz": 2621440, "linear_attention_total": 2621440, "linear_dense_nnz": 995328, "linear_dense_total": 8388608, "linear_nnz": 3616768, "linear_total": 11010048, "nnz": 1024, "total": 1024}, "11": {"linear_attention_nnz": 2621440, "linear_attention_total": 2621440, "linear_dense_nnz": 1032192, "linear_dense_total": 8388608, "linear_nnz": 3653632, "linear_total": 11010048, "nnz": 1024, "total": 1024}, "12": {"linear_attention_nnz": 3145728, "linear_attention_total": 3145728, "linear_dense_nnz": 1241088, "linear_dense_total": 8388608, "linear_nnz": 4386816, "linear_total": 11534336, "nnz": 1024, "total": 1024}, "13": {"linear_attention_nnz": 3145728, "linear_attention_total": 3145728, "linear_dense_nnz": 1179648, "linear_dense_total": 8388608, "linear_nnz": 4325376, "linear_total": 11534336, "nnz": 1024, "total": 1024}, "14": {"linear_attention_nnz": 2883584, "linear_attention_total": 2883584, "linear_dense_nnz": 909312, "linear_dense_total": 8388608, "linear_nnz": 3792896, "linear_total": 11272192, "nnz": 1024, "total": 1024}, "15": {"linear_attention_nnz": 2621440, "linear_attention_total": 2621440, "linear_dense_nnz": 681984, "linear_dense_total": 8388608, "linear_nnz": 3303424, "linear_total": 11010048, "nnz": 1024, "total": 1024}, "16": {"linear_attention_nnz": 2883584, "linear_attention_total": 2883584, "linear_dense_nnz": 473088, "linear_dense_total": 8388608, "linear_nnz": 3356672, "linear_total": 11272192, "nnz": 1024, "total": 1024}, "17": {"linear_attention_nnz": 2883584, "linear_attention_total": 2883584, "linear_dense_nnz": 368640, "linear_dense_total": 8388608, "linear_nnz": 3252224, "linear_total": 11272192, "nnz": 1024, "total": 1024}, "18": {"linear_attention_nnz": 2883584, "linear_attention_total": 2883584, "linear_dense_nnz": 321536, "linear_dense_total": 8388608, "linear_nnz": 3205120, "linear_total": 11272192, "nnz": 1024, "total": 1024}, "19": {"linear_attention_nnz": 2097152, "linear_attention_total": 2097152, "linear_dense_nnz": 270336, "linear_dense_total": 8388608, "linear_nnz": 2367488, "linear_total": 10485760, "nnz": 1024, "total": 1024}, "2": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 286720, "linear_dense_total": 8388608, "linear_nnz": 811008, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "20": {"linear_attention_nnz": 786432, "linear_attention_total": 786432, "linear_dense_nnz": 112640, "linear_dense_total": 8388608, "linear_nnz": 899072, "linear_total": 9175040, "nnz": 1024, "total": 1024}, "21": {"linear_attention_nnz": 1310720, "linear_attention_total": 1310720, "linear_dense_nnz": 77824, "linear_dense_total": 8388608, "linear_nnz": 1388544, "linear_total": 9699328, "nnz": 1024, "total": 1024}, "22": {"linear_attention_nnz": 786432, "linear_attention_total": 786432, "linear_dense_nnz": 79872, "linear_dense_total": 8388608, "linear_nnz": 866304, "linear_total": 9175040, "nnz": 1024, "total": 1024}, "23": {"linear_attention_nnz": 1048576, "linear_attention_total": 1048576, "linear_dense_nnz": 182272, "linear_dense_total": 8388608, "linear_nnz": 1230848, "linear_total": 9437184, "nnz": 1024, "total": 1024}, "3": {"linear_attention_nnz": 1310720, "linear_attention_total": 1310720, "linear_dense_nnz": 413696, "linear_dense_total": 8388608, "linear_nnz": 1724416, "linear_total": 9699328, "nnz": 1024, "total": 1024}, "4": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 466944, "linear_dense_total": 8388608, "linear_nnz": 991232, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "5": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 552960, "linear_dense_total": 8388608, "linear_nnz": 1077248, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "6": {"linear_attention_nnz": 786432, "linear_attention_total": 786432, "linear_dense_nnz": 608256, "linear_dense_total": 8388608, "linear_nnz": 1394688, "linear_total": 9175040, "nnz": 1024, "total": 1024}, "7": {"linear_attention_nnz": 1310720, "linear_attention_total": 1310720, "linear_dense_nnz": 438272, "linear_dense_total": 8388608, "linear_nnz": 1748992, "linear_total": 9699328, "nnz": 1024, "total": 1024}, "8": {"linear_attention_nnz": 1048576, "linear_attention_total": 1048576, "linear_dense_nnz": 661504, "linear_dense_total": 8388608, "linear_nnz": 1710080, "linear_total": 9437184, "nnz": 1024, "total": 1024}, "9": {"linear_attention_nnz": 1572864, "linear_attention_total": 1572864, "linear_dense_nnz": 747520, "linear_dense_total": 8388608, "linear_nnz": 2320384, "linear_total": 9961472, "nnz": 1024, "total": 1024}, "null": {"nnz": 2, "total": 2}}, "linear_nnz": 53983232, "linear_sparsity": 77.76137284017278, "linear_total": 242745344, "nnz": 85952121, "total": 274806402, "total_sparsity": 68.72266425583491}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_10", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 10, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_10", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_10", "save_steps": 2500, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 90.16320537561052, "fill_rate": 0.5930300575953924, "speedup": 1.0281280670181348}}
{"fill_rate": 0.5025114810562569, "f1": 89.39825688878855, "meta": {"annotate": "", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 3, 6, 7, 8, 10, 12, 13, 14], "11": [0, 1, 2, 4, 5, 6, 7, 8, 10, 12, 15], "12": [2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14], "13": [2, 3, 4, 10, 11, 12], "14": [1, 2, 3, 4, 8, 9, 11, 13], "15": [0, 1, 2, 5, 6, 7, 8, 9, 11, 12], "16": [3, 6, 7, 8, 10, 12, 13, 15], "17": [0, 2, 4, 11, 12, 15], "18": [2, 3, 5, 9, 11, 12, 13], "19": [0, 1, 2, 3, 4, 5, 9, 10, 11, 13, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "21": [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14], "23": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 82.32734153263955, "f1": 89.39825688878855}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_40_d0.25/checkpoint-52500", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_40_d0.25/checkpoint-220000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 29.977725273132325, "eval_elapsed_time": 37.05464425915852}, "speedup": 1.2874356761138743, "stats": {"layers": {"0": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 253952, "linear_dense_total": 8388608, "linear_nnz": 778240, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "1": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 432128, "linear_dense_total": 8388608, "linear_nnz": 956416, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "10": {"linear_attention_nnz": 1835008, "linear_attention_total": 1835008, "linear_dense_nnz": 1210368, "linear_dense_total": 8388608, "linear_nnz": 3045376, "linear_total": 10223616, "nnz": 1024, "total": 1024}, "11": {"linear_attention_nnz": 1310720, "linear_attention_total": 1310720, "linear_dense_nnz": 1277952, "linear_dense_total": 8388608, "linear_nnz": 2588672, "linear_total": 9699328, "nnz": 1024, "total": 1024}, "12": {"linear_attention_nnz": 1310720, "linear_attention_total": 1310720, "linear_dense_nnz": 1400832, "linear_dense_total": 8388608, "linear_nnz": 2711552, "linear_total": 9699328, "nnz": 1024, "total": 1024}, "13": {"linear_attention_nnz": 2621440, "linear_attention_total": 2621440, "linear_dense_nnz": 1464320, "linear_dense_total": 8388608, "linear_nnz": 4085760, "linear_total": 11010048, "nnz": 1024, "total": 1024}, "14": {"linear_attention_nnz": 2097152, "linear_attention_total": 2097152, "linear_dense_nnz": 1122304, "linear_dense_total": 8388608, "linear_nnz": 3219456, "linear_total": 10485760, "nnz": 1024, "total": 1024}, "15": {"linear_attention_nnz": 1572864, "linear_attention_total": 1572864, "linear_dense_nnz": 778240, "linear_dense_total": 8388608, "linear_nnz": 2351104, "linear_total": 9961472, "nnz": 1024, "total": 1024}, "16": {"linear_attention_nnz": 2097152, "linear_attention_total": 2097152, "linear_dense_nnz": 532480, "linear_dense_total": 8388608, "linear_nnz": 2629632, "linear_total": 10485760, "nnz": 1024, "total": 1024}, "17": {"linear_attention_nnz": 2621440, "linear_attention_total": 2621440, "linear_dense_nnz": 456704, "linear_dense_total": 8388608, "linear_nnz": 3078144, "linear_total": 11010048, "nnz": 1024, "total": 1024}, "18": {"linear_attention_nnz": 2359296, "linear_attention_total": 2359296, "linear_dense_nnz": 440320, "linear_dense_total": 8388608, "linear_nnz": 2799616, "linear_total": 10747904, "nnz": 1024, "total": 1024}, "19": {"linear_attention_nnz": 1310720, "linear_attention_total": 1310720, "linear_dense_nnz": 362496, "linear_dense_total": 8388608, "linear_nnz": 1673216, "linear_total": 9699328, "nnz": 1024, "total": 1024}, "2": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 450560, "linear_dense_total": 8388608, "linear_nnz": 974848, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "20": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 184320, "linear_dense_total": 8388608, "linear_nnz": 708608, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "21": {"linear_attention_nnz": 786432, "linear_attention_total": 786432, "linear_dense_nnz": 112640, "linear_dense_total": 8388608, "linear_nnz": 899072, "linear_total": 9175040, "nnz": 1024, "total": 1024}, "22": {"linear_attention_nnz": 786432, "linear_attention_total": 786432, "linear_dense_nnz": 114688, "linear_dense_total": 8388608, "linear_nnz": 901120, "linear_total": 9175040, "nnz": 1024, "total": 1024}, "23": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 184320, "linear_dense_total": 8388608, "linear_nnz": 708608, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "3": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 548864, "linear_dense_total": 8388608, "linear_nnz": 1073152, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "4": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 614400, "linear_dense_total": 8388608, "linear_nnz": 1138688, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "5": {"linear_attention_nnz": 262144, "linear_attention_total": 262144, "linear_dense_nnz": 839680, "linear_dense_total": 8388608, "linear_nnz": 1101824, "linear_total": 8650752, "nnz": 1024, "total": 1024}, "6": {"linear_attention_nnz": 262144, "linear_attention_total": 262144, "linear_dense_nnz": 858112, "linear_dense_total": 8388608, "linear_nnz": 1120256, "linear_total": 8650752, "nnz": 1024, "total": 1024}, "7": {"linear_attention_nnz": 786432, "linear_attention_total": 786432, "linear_dense_nnz": 636928, "linear_dense_total": 8388608, "linear_nnz": 1423360, "linear_total": 9175040, "nnz": 1024, "total": 1024}, "8": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 847872, "linear_dense_total": 8388608, "linear_nnz": 1372160, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "9": {"linear_attention_nnz": 786432, "linear_attention_total": 786432, "linear_dense_nnz": 901120, "linear_dense_total": 8388608, "linear_nnz": 1687552, "linear_total": 9175040, "nnz": 1024, "total": 1024}, "null": {"nnz": 2, "total": 2}}, "linear_nnz": 43026432, "linear_sparsity": 81.15581946039036, "linear_total": 228327424, "nnz": 74986451, "total": 260377922, "total_sparsity": 71.20091810241884}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_40_d0.25", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 10, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_40_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_40_d0.25", "save_steps": 2500, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 89.39825688878855, "fill_rate": 0.5025114810562569, "speedup": 1.2874356761138743}}
{"fill_rate": 0.40262012864169494, "f1": 88.34901265417608, "meta": {"annotate": "", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [1, 2, 3, 4, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 3, 6, 7, 8, 10, 12, 13, 14], "11": [0, 1, 2, 4, 5, 6, 8, 10, 12], "12": [1, 2, 3, 5, 6, 7, 8, 10, 12, 13, 14], "13": [2, 3, 4, 10, 11, 12], "14": [1, 2, 3, 4, 8, 11], "15": [0, 2, 5, 6, 7, 8, 9, 11, 12], "16": [3, 6, 8, 10, 12, 13, 15], "17": [0, 2, 4, 11, 12, 15], "18": [2, 3, 5, 9, 11, 12, 13], "19": [0, 1, 2, 3, 4, 5, 9, 10, 11, 13, 14, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "23": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 6, 8, 10, 11, 12, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 81.15421002838221, "f1": 88.34901265417608}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_40/checkpoint-55330", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_40/checkpoint-221320", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 28.669108856201174, "eval_elapsed_time": 35.70603838330135}, "speedup": 1.3462013485997515, "stats": {"layers": {"0": {"linear_attention_nnz": 1048576, "linear_attention_total": 1048576, "linear_dense_nnz": 88064, "linear_dense_total": 8388608, "linear_nnz": 1136640, "linear_total": 9437184, "nnz": 1024, "total": 1024}, "1": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 102400, "linear_dense_total": 8388608, "linear_nnz": 626688, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "10": {"linear_attention_nnz": 1835008, "linear_attention_total": 1835008, "linear_dense_nnz": 442368, "linear_dense_total": 8388608, "linear_nnz": 2277376, "linear_total": 10223616, "nnz": 1024, "total": 1024}, "11": {"linear_attention_nnz": 1835008, "linear_attention_total": 1835008, "linear_dense_nnz": 462848, "linear_dense_total": 8388608, "linear_nnz": 2297856, "linear_total": 10223616, "nnz": 1024, "total": 1024}, "12": {"linear_attention_nnz": 1310720, "linear_attention_total": 1310720, "linear_dense_nnz": 557056, "linear_dense_total": 8388608, "linear_nnz": 1867776, "linear_total": 9699328, "nnz": 1024, "total": 1024}, "13": {"linear_attention_nnz": 2621440, "linear_attention_total": 2621440, "linear_dense_nnz": 507904, "linear_dense_total": 8388608, "linear_nnz": 3129344, "linear_total": 11010048, "nnz": 1024, "total": 1024}, "14": {"linear_attention_nnz": 2621440, "linear_attention_total": 2621440, "linear_dense_nnz": 362496, "linear_dense_total": 8388608, "linear_nnz": 2983936, "linear_total": 11010048, "nnz": 1024, "total": 1024}, "15": {"linear_attention_nnz": 1835008, "linear_attention_total": 1835008, "linear_dense_nnz": 278528, "linear_dense_total": 8388608, "linear_nnz": 2113536, "linear_total": 10223616, "nnz": 1024, "total": 1024}, "16": {"linear_attention_nnz": 2359296, "linear_attention_total": 2359296, "linear_dense_nnz": 188416, "linear_dense_total": 8388608, "linear_nnz": 2547712, "linear_total": 10747904, "nnz": 1024, "total": 1024}, "17": {"linear_attention_nnz": 2621440, "linear_attention_total": 2621440, "linear_dense_nnz": 188416, "linear_dense_total": 8388608, "linear_nnz": 2809856, "linear_total": 11010048, "nnz": 1024, "total": 1024}, "18": {"linear_attention_nnz": 2359296, "linear_attention_total": 2359296, "linear_dense_nnz": 141312, "linear_dense_total": 8388608, "linear_nnz": 2500608, "linear_total": 10747904, "nnz": 1024, "total": 1024}, "19": {"linear_attention_nnz": 1048576, "linear_attention_total": 1048576, "linear_dense_nnz": 137216, "linear_dense_total": 8388608, "linear_nnz": 1185792, "linear_total": 9437184, "nnz": 1024, "total": 1024}, "2": {"linear_attention_nnz": 262144, "linear_attention_total": 262144, "linear_dense_nnz": 90112, "linear_dense_total": 8388608, "linear_nnz": 352256, "linear_total": 8650752, "nnz": 1024, "total": 1024}, "20": {"linear_attention_nnz": 786432, "linear_attention_total": 786432, "linear_dense_nnz": 57344, "linear_dense_total": 8388608, "linear_nnz": 843776, "linear_total": 9175040, "nnz": 1024, "total": 1024}, "21": {"linear_attention_nnz": 786432, "linear_attention_total": 786432, "linear_dense_nnz": 40960, "linear_dense_total": 8388608, "linear_nnz": 827392, "linear_total": 9175040, "nnz": 1024, "total": 1024}, "22": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 40960, "linear_dense_total": 8388608, "linear_nnz": 565248, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "23": {"linear_attention_nnz": 786432, "linear_attention_total": 786432, "linear_dense_nnz": 102400, "linear_dense_total": 8388608, "linear_nnz": 888832, "linear_total": 9175040, "nnz": 1024, "total": 1024}, "3": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 155648, "linear_dense_total": 8388608, "linear_nnz": 679936, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "4": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 143360, "linear_dense_total": 8388608, "linear_nnz": 667648, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "5": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 167936, "linear_dense_total": 8388608, "linear_nnz": 692224, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "6": {"linear_attention_nnz": 262144, "linear_attention_total": 262144, "linear_dense_nnz": 212992, "linear_dense_total": 8388608, "linear_nnz": 475136, "linear_total": 8650752, "nnz": 1024, "total": 1024}, "7": {"linear_attention_nnz": 1048576, "linear_attention_total": 1048576, "linear_dense_nnz": 178176, "linear_dense_total": 8388608, "linear_nnz": 1226752, "linear_total": 9437184, "nnz": 1024, "total": 1024}, "8": {"linear_attention_nnz": 524288, "linear_attention_total": 524288, "linear_dense_nnz": 229376, "linear_dense_total": 8388608, "linear_nnz": 753664, "linear_total": 8912896, "nnz": 1024, "total": 1024}, "9": {"linear_attention_nnz": 1048576, "linear_attention_total": 1048576, "linear_dense_nnz": 370688, "linear_dense_total": 8388608, "linear_nnz": 1419264, "linear_total": 9437184, "nnz": 1024, "total": 1024}, "null": {"nnz": 2, "total": 2}}, "linear_nnz": 34869248, "linear_sparsity": 84.90174517593644, "linear_total": 230948864, "nnz": 66825924, "total": 263001282, "total_sparsity": 74.59102727871874}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_40", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 10, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_40", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_large_regu_40", "save_steps": 2500, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 88.34901265417608, "fill_rate": 0.40262012864169494, "speedup": 1.3462013485997515}}
