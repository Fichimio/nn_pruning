{"fill_rate": 0.5761748890817902, "f1": 88.34112193061533, "meta": {"fill_rate": 0.5761748890817902, "speedup": 1.2806693802635063, "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.93661305581836, "f1": 88.34112193061533}, "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 16, "attention_block_rows": 16, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 16, "dense_block_rows": 16, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 30.13610975646973, "eval_elapsed_time": 37.54532916797325}, "speedup": 1.2806693802635063, "stats": {"layers": {"0": {"linear_attention_nnz": 517888, "linear_attention_total": 2359296, "linear_dense_nnz": 4068608, "linear_dense_total": 4718592, "linear_nnz": 4586496, "linear_total": 7077888, "nnz": 4594896, "total": 7087872}, "1": {"linear_attention_nnz": 641536, "linear_attention_total": 2359296, "linear_dense_nnz": 4202752, "linear_dense_total": 4718592, "linear_nnz": 4844288, "linear_total": 7077888, "nnz": 4852816, "total": 7087872}, "10": {"linear_attention_nnz": 415488, "linear_attention_total": 2359296, "linear_dense_nnz": 1090304, "linear_dense_total": 4718592, "linear_nnz": 1505792, "linear_total": 7077888, "nnz": 1513344, "total": 7087872}, "11": {"linear_attention_nnz": 254720, "linear_attention_total": 2359296, "linear_dense_nnz": 947200, "linear_dense_total": 4718592, "linear_nnz": 1201920, "linear_total": 7077888, "nnz": 1208720, "total": 7087872}, "2": {"linear_attention_nnz": 841472, "linear_attention_total": 2359296, "linear_dense_nnz": 4313856, "linear_dense_total": 4718592, "linear_nnz": 5155328, "linear_total": 7077888, "nnz": 5164240, "total": 7087872}, "3": {"linear_attention_nnz": 1072896, "linear_attention_total": 2359296, "linear_dense_nnz": 4336128, "linear_dense_total": 4718592, "linear_nnz": 5409024, "linear_total": 7077888, "nnz": 5418160, "total": 7087872}, "4": {"linear_attention_nnz": 1068800, "linear_attention_total": 2359296, "linear_dense_nnz": 4317184, "linear_dense_total": 4718592, "linear_nnz": 5385984, "linear_total": 7077888, "nnz": 5395264, "total": 7087872}, "5": {"linear_attention_nnz": 961792, "linear_attention_total": 2359296, "linear_dense_nnz": 4311040, "linear_dense_total": 4718592, "linear_nnz": 5272832, "linear_total": 7077888, "nnz": 5281824, "total": 7087872}, "6": {"linear_attention_nnz": 986880, "linear_attention_total": 2359296, "linear_dense_nnz": 4141568, "linear_dense_total": 4718592, "linear_nnz": 5128448, "linear_total": 7077888, "nnz": 5137632, "total": 7087872}, "7": {"linear_attention_nnz": 905472, "linear_attention_total": 2359296, "linear_dense_nnz": 3820032, "linear_dense_total": 4718592, "linear_nnz": 4725504, "linear_total": 7077888, "nnz": 4734512, "total": 7087872}, "8": {"linear_attention_nnz": 756224, "linear_attention_total": 2359296, "linear_dense_nnz": 3085568, "linear_dense_total": 4718592, "linear_nnz": 3841792, "linear_total": 7077888, "nnz": 3850720, "total": 7087872}, "9": {"linear_attention_nnz": 463360, "linear_attention_total": 2359296, "linear_dense_nnz": 1416448, "linear_dense_total": 4718592, "linear_nnz": 1879808, "linear_total": 7077888, "nnz": 1887632, "total": 7087872}}, "linear_nnz": 48937216, "linear_sparsity": 42.38251109182099, "linear_total": 84934656, "nnz": 72878482, "pruned_heads": {"0": [2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [1, 2], "5": [1, 2, 6, 7, 11], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 8, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 33.07342297799975}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/opt/ml/model", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v9-a16-l10--2021-01-20--18-58-11/checkpoint-110660"}, "f1": 88.34112193061533, "cat_fun_name": "is_full_block", "annotate": "57"}}
{"fill_rate": 0.46761670524691357, "f1": 87.51569063636161, "meta": {"fill_rate": 0.46761670524691357, "speedup": 1.4644339860190774, "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.02838221381268, "f1": 87.51569063636161}, "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 16, "attention_block_rows": 16, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 16, "dense_block_rows": 16, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20.0}, "speed": {"cuda_eval_elapsed_time": 26.3544778213501, "eval_elapsed_time": 33.69302155217156}, "speedup": 1.4644339860190774, "stats": {"layers": {"0": {"linear_attention_nnz": 417024, "linear_attention_total": 2359296, "linear_dense_nnz": 3447808, "linear_dense_total": 4718592, "linear_nnz": 3864832, "linear_total": 7077888, "nnz": 3873088, "total": 7087872}, "1": {"linear_attention_nnz": 542720, "linear_attention_total": 2359296, "linear_dense_nnz": 3703296, "linear_dense_total": 4718592, "linear_nnz": 4246016, "linear_total": 7077888, "nnz": 4254480, "total": 7087872}, "10": {"linear_attention_nnz": 273408, "linear_attention_total": 2359296, "linear_dense_nnz": 647424, "linear_dense_total": 4718592, "linear_nnz": 920832, "linear_total": 7077888, "nnz": 927232, "total": 7087872}, "11": {"linear_attention_nnz": 166400, "linear_attention_total": 2359296, "linear_dense_nnz": 608512, "linear_dense_total": 4718592, "linear_nnz": 774912, "linear_total": 7077888, "nnz": 781008, "total": 7087872}, "2": {"linear_attention_nnz": 555776, "linear_attention_total": 2359296, "linear_dense_nnz": 3981824, "linear_dense_total": 4718592, "linear_nnz": 4537600, "linear_total": 7077888, "nnz": 4546144, "total": 7087872}, "3": {"linear_attention_nnz": 810240, "linear_attention_total": 2359296, "linear_dense_nnz": 4014336, "linear_dense_total": 4718592, "linear_nnz": 4824576, "linear_total": 7077888, "nnz": 4833424, "total": 7087872}, "4": {"linear_attention_nnz": 764160, "linear_attention_total": 2359296, "linear_dense_nnz": 3940608, "linear_dense_total": 4718592, "linear_nnz": 4704768, "linear_total": 7077888, "nnz": 4713616, "total": 7087872}, "5": {"linear_attention_nnz": 685824, "linear_attention_total": 2359296, "linear_dense_nnz": 3904256, "linear_dense_total": 4718592, "linear_nnz": 4590080, "linear_total": 7077888, "nnz": 4598784, "total": 7087872}, "6": {"linear_attention_nnz": 647680, "linear_attention_total": 2359296, "linear_dense_nnz": 3571456, "linear_dense_total": 4718592, "linear_nnz": 4219136, "linear_total": 7077888, "nnz": 4227936, "total": 7087872}, "7": {"linear_attention_nnz": 684288, "linear_attention_total": 2359296, "linear_dense_nnz": 2956288, "linear_dense_total": 4718592, "linear_nnz": 3640576, "linear_total": 7077888, "nnz": 3649248, "total": 7087872}, "8": {"linear_attention_nnz": 427264, "linear_attention_total": 2359296, "linear_dense_nnz": 1932800, "linear_dense_total": 4718592, "linear_nnz": 2360064, "linear_total": 7077888, "nnz": 2368032, "total": 7087872}, "9": {"linear_attention_nnz": 350976, "linear_attention_total": 2359296, "linear_dense_nnz": 682496, "linear_dense_total": 4718592, "linear_nnz": 1033472, "linear_total": 7077888, "nnz": 1039984, "total": 7087872}}, "linear_nnz": 39716864, "linear_sparsity": 53.238329475308646, "linear_total": 84934656, "nnz": 63651698, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 3, 4, 7, 8], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 11], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 5, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 41.546665739029805}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/opt/ml/model", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v9-a16-l20--2021-01-20--18-58-39/checkpoint-105000"}, "f1": 87.51569063636161, "cat_fun_name": "is_full_block", "annotate": "46"}}
{"fill_rate": 0.344922477816358, "f1": 86.14927876930865, "meta": {"fill_rate": 0.344922477816358, "speedup": 1.6527498971607057, "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.11731315042573, "f1": 86.14927876930865}, "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 16, "attention_block_rows": 16, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 16, "dense_block_rows": 16, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 40.0}, "speed": {"cuda_eval_elapsed_time": 23.35162329864502, "eval_elapsed_time": 30.60480569722131}, "speedup": 1.6527498971607057, "stats": {"layers": {"0": {"linear_attention_nnz": 331008, "linear_attention_total": 2359296, "linear_dense_nnz": 2354688, "linear_dense_total": 4718592, "linear_nnz": 2685696, "linear_total": 7077888, "nnz": 2693408, "total": 7087872}, "1": {"linear_attention_nnz": 432384, "linear_attention_total": 2359296, "linear_dense_nnz": 2826240, "linear_dense_total": 4718592, "linear_nnz": 3258624, "linear_total": 7077888, "nnz": 3266704, "total": 7087872}, "10": {"linear_attention_nnz": 203008, "linear_attention_total": 2359296, "linear_dense_nnz": 415744, "linear_dense_total": 4718592, "linear_nnz": 618752, "linear_total": 7077888, "nnz": 624640, "total": 7087872}, "11": {"linear_attention_nnz": 112128, "linear_attention_total": 2359296, "linear_dense_nnz": 423168, "linear_dense_total": 4718592, "linear_nnz": 535296, "linear_total": 7077888, "nnz": 540768, "total": 7087872}, "2": {"linear_attention_nnz": 423936, "linear_attention_total": 2359296, "linear_dense_nnz": 3302144, "linear_dense_total": 4718592, "linear_nnz": 3726080, "linear_total": 7077888, "nnz": 3734288, "total": 7087872}, "3": {"linear_attention_nnz": 669440, "linear_attention_total": 2359296, "linear_dense_nnz": 3248128, "linear_dense_total": 4718592, "linear_nnz": 3917568, "linear_total": 7077888, "nnz": 3926240, "total": 7087872}, "4": {"linear_attention_nnz": 453632, "linear_attention_total": 2359296, "linear_dense_nnz": 3193600, "linear_dense_total": 4718592, "linear_nnz": 3647232, "linear_total": 7077888, "nnz": 3655504, "total": 7087872}, "5": {"linear_attention_nnz": 473856, "linear_attention_total": 2359296, "linear_dense_nnz": 3119616, "linear_dense_total": 4718592, "linear_nnz": 3593472, "linear_total": 7077888, "nnz": 3601824, "total": 7087872}, "6": {"linear_attention_nnz": 445952, "linear_attention_total": 2359296, "linear_dense_nnz": 2493696, "linear_dense_total": 4718592, "linear_nnz": 2939648, "linear_total": 7077888, "nnz": 2947744, "total": 7087872}, "7": {"linear_attention_nnz": 490752, "linear_attention_total": 2359296, "linear_dense_nnz": 1891072, "linear_dense_total": 4718592, "linear_nnz": 2381824, "linear_total": 7077888, "nnz": 2389520, "total": 7087872}, "8": {"linear_attention_nnz": 275712, "linear_attention_total": 2359296, "linear_dense_nnz": 1108736, "linear_dense_total": 4718592, "linear_nnz": 1384448, "linear_total": 7077888, "nnz": 1391248, "total": 7087872}, "9": {"linear_attention_nnz": 258304, "linear_attention_total": 2359296, "linear_dense_nnz": 348928, "linear_dense_total": 4718592, "linear_nnz": 607232, "linear_total": 7077888, "nnz": 612928, "total": 7087872}}, "linear_nnz": 29295872, "linear_sparsity": 65.5077522183642, "linear_total": 84934656, "nnz": 53223538, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 3, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 7, 8, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 1, 2, 3, 4, 5, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 51.12316945157615}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/opt/ml/model", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v9-a16-l40--2021-01-20--18-59-08/checkpoint-110660"}, "f1": 86.14927876930865, "cat_fun_name": "is_full_block", "annotate": "34"}}
