{"speedup": 1.1252216532791355, "f1": 88.58172107792693, "meta": {"fill_rate": 0.576706686137635, "speedup": 1.1252216532791355, "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 81.47587511825922, "f1": 88.58172107792693}, "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 4, "attention_block_rows": 4, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 4, "dense_block_rows": 4, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 34.2993692779541, "eval_elapsed_time": 41.87211530236527}, "speedup": 1.1252216532791355, "stats": {"layers": {"0": {"linear_attention_nnz": 428592, "linear_attention_total": 2359296, "linear_dense_nnz": 3980096, "linear_dense_total": 4718592, "linear_nnz": 4408688, "linear_total": 7077888, "nnz": 4417456, "total": 7087872}, "1": {"linear_attention_nnz": 545744, "linear_attention_total": 2359296, "linear_dense_nnz": 4015584, "linear_dense_total": 4718592, "linear_nnz": 4561328, "linear_total": 7077888, "nnz": 4570120, "total": 7087872}, "10": {"linear_attention_nnz": 329968, "linear_attention_total": 2359296, "linear_dense_nnz": 2092032, "linear_dense_total": 4718592, "linear_nnz": 2422000, "linear_total": 7077888, "nnz": 2430724, "total": 7087872}, "11": {"linear_attention_nnz": 190816, "linear_attention_total": 2359296, "linear_dense_nnz": 1335104, "linear_dense_total": 4718592, "linear_nnz": 1525920, "linear_total": 7077888, "nnz": 1534052, "total": 7087872}, "2": {"linear_attention_nnz": 729664, "linear_attention_total": 2359296, "linear_dense_nnz": 4061440, "linear_dense_total": 4718592, "linear_nnz": 4791104, "linear_total": 7077888, "nnz": 4800292, "total": 7087872}, "3": {"linear_attention_nnz": 851472, "linear_attention_total": 2359296, "linear_dense_nnz": 4062640, "linear_dense_total": 4718592, "linear_nnz": 4914112, "linear_total": 7077888, "nnz": 4923388, "total": 7087872}, "4": {"linear_attention_nnz": 960992, "linear_attention_total": 2359296, "linear_dense_nnz": 4047744, "linear_dense_total": 4718592, "linear_nnz": 5008736, "linear_total": 7077888, "nnz": 5018448, "total": 7087872}, "5": {"linear_attention_nnz": 902768, "linear_attention_total": 2359296, "linear_dense_nnz": 4006096, "linear_dense_total": 4718592, "linear_nnz": 4908864, "linear_total": 7077888, "nnz": 4918468, "total": 7087872}, "6": {"linear_attention_nnz": 861120, "linear_attention_total": 2359296, "linear_dense_nnz": 3920672, "linear_dense_total": 4718592, "linear_nnz": 4781792, "linear_total": 7077888, "nnz": 4791412, "total": 7087872}, "7": {"linear_attention_nnz": 759664, "linear_attention_total": 2359296, "linear_dense_nnz": 3732848, "linear_dense_total": 4718592, "linear_nnz": 4492512, "linear_total": 7077888, "nnz": 4501704, "total": 7087872}, "8": {"linear_attention_nnz": 670096, "linear_attention_total": 2359296, "linear_dense_nnz": 3391392, "linear_dense_total": 4718592, "linear_nnz": 4061488, "linear_total": 7077888, "nnz": 4070864, "total": 7087872}, "9": {"linear_attention_nnz": 444064, "linear_attention_total": 2359296, "linear_dense_nnz": 2661776, "linear_dense_total": 4718592, "linear_nnz": 3105840, "linear_total": 7077888, "nnz": 3114612, "total": 7087872}}, "linear_nnz": 48982384, "linear_sparsity": 42.329331386236504, "linear_total": 84934656, "nnz": 72930262, "pruned_heads": {"0": [9], "1": [0, 8, 2], "10": [1, 4, 5, 6, 7, 8], "11": [0, 5, 7, 8, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [], "5": [1], "6": [3], "7": [11, 3, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 33.025871793300276}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/opt/ml/model", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v9-a4-l10--2021-01-20--19-01-04/checkpoint-110660"}, "f1": 88.58172107792693, "cat_fun_name": "is_full_block", "annotate": "57"}}
{"speedup": 1.1931736074335828, "f1": 88.02284574429551, "meta": {"fill_rate": 0.4656780855155285, "speedup": 1.1931736074335828, "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.52980132450331, "f1": 88.02284574429551}, "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 4, "attention_block_rows": 4, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 4, "dense_block_rows": 4, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20.0}, "speed": {"cuda_eval_elapsed_time": 32.3459995803833, "eval_elapsed_time": 40.03914254019037}, "speedup": 1.1931736074335828, "stats": {"layers": {"0": {"linear_attention_nnz": 258016, "linear_attention_total": 2359296, "linear_dense_nnz": 3584960, "linear_dense_total": 4718592, "linear_nnz": 3842976, "linear_total": 7077888, "nnz": 3851352, "total": 7087872}, "1": {"linear_attention_nnz": 404784, "linear_attention_total": 2359296, "linear_dense_nnz": 3659360, "linear_dense_total": 4718592, "linear_nnz": 4064144, "linear_total": 7077888, "nnz": 4072688, "total": 7087872}, "10": {"linear_attention_nnz": 209136, "linear_attention_total": 2359296, "linear_dense_nnz": 1083920, "linear_dense_total": 4718592, "linear_nnz": 1293056, "linear_total": 7077888, "nnz": 1301528, "total": 7087872}, "11": {"linear_attention_nnz": 120976, "linear_attention_total": 2359296, "linear_dense_nnz": 697408, "linear_dense_total": 4718592, "linear_nnz": 818384, "linear_total": 7077888, "nnz": 825580, "total": 7087872}, "2": {"linear_attention_nnz": 460752, "linear_attention_total": 2359296, "linear_dense_nnz": 3741328, "linear_dense_total": 4718592, "linear_nnz": 4202080, "linear_total": 7077888, "nnz": 4211032, "total": 7087872}, "3": {"linear_attention_nnz": 577184, "linear_attention_total": 2359296, "linear_dense_nnz": 3724032, "linear_dense_total": 4718592, "linear_nnz": 4301216, "linear_total": 7077888, "nnz": 4310276, "total": 7087872}, "4": {"linear_attention_nnz": 587792, "linear_attention_total": 2359296, "linear_dense_nnz": 3689648, "linear_dense_total": 4718592, "linear_nnz": 4277440, "linear_total": 7077888, "nnz": 4286684, "total": 7087872}, "5": {"linear_attention_nnz": 530480, "linear_attention_total": 2359296, "linear_dense_nnz": 3641984, "linear_dense_total": 4718592, "linear_nnz": 4172464, "linear_total": 7077888, "nnz": 4181480, "total": 7087872}, "6": {"linear_attention_nnz": 508336, "linear_attention_total": 2359296, "linear_dense_nnz": 3491408, "linear_dense_total": 4718592, "linear_nnz": 3999744, "linear_total": 7077888, "nnz": 4008976, "total": 7087872}, "7": {"linear_attention_nnz": 486304, "linear_attention_total": 2359296, "linear_dense_nnz": 3187056, "linear_dense_total": 4718592, "linear_nnz": 3673360, "linear_total": 7077888, "nnz": 3682292, "total": 7087872}, "8": {"linear_attention_nnz": 374032, "linear_attention_total": 2359296, "linear_dense_nnz": 2669344, "linear_dense_total": 4718592, "linear_nnz": 3043376, "linear_total": 7077888, "nnz": 3052288, "total": 7087872}, "9": {"linear_attention_nnz": 276992, "linear_attention_total": 2359296, "linear_dense_nnz": 1586976, "linear_dense_total": 4718592, "linear_nnz": 1863968, "linear_total": 7077888, "nnz": 1872484, "total": 7087872}}, "linear_nnz": 39552208, "linear_sparsity": 53.432191448447156, "linear_total": 84934656, "nnz": 63495382, "pruned_heads": {"0": [9, 2, 4, 5], "1": [0, 8, 2, 6], "10": [1, 4, 5, 6, 7, 8], "11": [0, 5, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [6], "5": [1, 2, 6, 7], "6": [2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 41.69021558428826}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/opt/ml/model", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v9-a4-l20--2021-01-20--19-01-34/checkpoint-105000"}, "f1": 88.02284574429551, "cat_fun_name": "is_full_block", "annotate": "46"}}
{"speedup": 1.1988795413397866, "f1": 87.80889686617203, "meta": {"fill_rate": 0.4656780855155285, "speedup": 1.1988795413397866, "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.09460737937559, "f1": 87.80889686617203}, "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 4, "attention_block_rows": 4, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 4, "dense_block_rows": 4, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20.0}, "speed": {"cuda_eval_elapsed_time": 32.19205239105224, "eval_elapsed_time": 39.82947535999119}, "speedup": 1.1988795413397866, "stats": {"layers": {"0": {"linear_attention_nnz": 258016, "linear_attention_total": 2359296, "linear_dense_nnz": 3584960, "linear_dense_total": 4718592, "linear_nnz": 3842976, "linear_total": 7077888, "nnz": 3851352, "total": 7087872}, "1": {"linear_attention_nnz": 404784, "linear_attention_total": 2359296, "linear_dense_nnz": 3659360, "linear_dense_total": 4718592, "linear_nnz": 4064144, "linear_total": 7077888, "nnz": 4072688, "total": 7087872}, "10": {"linear_attention_nnz": 209136, "linear_attention_total": 2359296, "linear_dense_nnz": 1083920, "linear_dense_total": 4718592, "linear_nnz": 1293056, "linear_total": 7077888, "nnz": 1301528, "total": 7087872}, "11": {"linear_attention_nnz": 120976, "linear_attention_total": 2359296, "linear_dense_nnz": 697408, "linear_dense_total": 4718592, "linear_nnz": 818384, "linear_total": 7077888, "nnz": 825580, "total": 7087872}, "2": {"linear_attention_nnz": 460752, "linear_attention_total": 2359296, "linear_dense_nnz": 3741328, "linear_dense_total": 4718592, "linear_nnz": 4202080, "linear_total": 7077888, "nnz": 4211032, "total": 7087872}, "3": {"linear_attention_nnz": 577184, "linear_attention_total": 2359296, "linear_dense_nnz": 3724032, "linear_dense_total": 4718592, "linear_nnz": 4301216, "linear_total": 7077888, "nnz": 4310276, "total": 7087872}, "4": {"linear_attention_nnz": 587792, "linear_attention_total": 2359296, "linear_dense_nnz": 3689648, "linear_dense_total": 4718592, "linear_nnz": 4277440, "linear_total": 7077888, "nnz": 4286684, "total": 7087872}, "5": {"linear_attention_nnz": 530480, "linear_attention_total": 2359296, "linear_dense_nnz": 3641984, "linear_dense_total": 4718592, "linear_nnz": 4172464, "linear_total": 7077888, "nnz": 4181480, "total": 7087872}, "6": {"linear_attention_nnz": 508336, "linear_attention_total": 2359296, "linear_dense_nnz": 3491408, "linear_dense_total": 4718592, "linear_nnz": 3999744, "linear_total": 7077888, "nnz": 4008976, "total": 7087872}, "7": {"linear_attention_nnz": 486304, "linear_attention_total": 2359296, "linear_dense_nnz": 3187056, "linear_dense_total": 4718592, "linear_nnz": 3673360, "linear_total": 7077888, "nnz": 3682292, "total": 7087872}, "8": {"linear_attention_nnz": 374032, "linear_attention_total": 2359296, "linear_dense_nnz": 2669344, "linear_dense_total": 4718592, "linear_nnz": 3043376, "linear_total": 7077888, "nnz": 3052288, "total": 7087872}, "9": {"linear_attention_nnz": 276992, "linear_attention_total": 2359296, "linear_dense_nnz": 1586976, "linear_dense_total": 4718592, "linear_nnz": 1863968, "linear_total": 7077888, "nnz": 1872484, "total": 7087872}}, "linear_nnz": 39552208, "linear_sparsity": 53.432191448447156, "linear_total": 84934656, "nnz": 63495382, "pruned_heads": {"0": [9, 2, 4, 5], "1": [0, 8, 2, 6], "10": [1, 4, 5, 6, 7, 8], "11": [0, 5, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [6], "5": [1, 2, 6, 7], "6": [2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 41.69021558428826}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/opt/ml/model", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v9-a4-l20--2021-01-20--19-01-34/checkpoint-110660"}, "f1": 87.80889686617203, "cat_fun_name": "is_full_block", "annotate": "46"}}
{"speedup": 1.3515039902008532, "f1": 87.31499809166372, "meta": {"fill_rate": 0.352672435619213, "speedup": 1.3515039902008532, "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.64049195837275, "f1": 87.31499809166372}, "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 4, "attention_block_rows": 4, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 4, "dense_block_rows": 4, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 40.0}, "speed": {"cuda_eval_elapsed_time": 28.556625274658202, "eval_elapsed_time": 36.13367621740326}, "speedup": 1.3515039902008532, "stats": {"layers": {"0": {"linear_attention_nnz": 169136, "linear_attention_total": 2359296, "linear_dense_nnz": 2961360, "linear_dense_total": 4718592, "linear_nnz": 3130496, "linear_total": 7077888, "nnz": 3138744, "total": 7087872}, "1": {"linear_attention_nnz": 304464, "linear_attention_total": 2359296, "linear_dense_nnz": 3089024, "linear_dense_total": 4718592, "linear_nnz": 3393488, "linear_total": 7077888, "nnz": 3401900, "total": 7087872}, "10": {"linear_attention_nnz": 137920, "linear_attention_total": 2359296, "linear_dense_nnz": 522400, "linear_dense_total": 4718592, "linear_nnz": 660320, "linear_total": 7077888, "nnz": 667764, "total": 7087872}, "11": {"linear_attention_nnz": 82480, "linear_attention_total": 2359296, "linear_dense_nnz": 374544, "linear_dense_total": 4718592, "linear_nnz": 457024, "linear_total": 7077888, "nnz": 463412, "total": 7087872}, "2": {"linear_attention_nnz": 279216, "linear_attention_total": 2359296, "linear_dense_nnz": 3191664, "linear_dense_total": 4718592, "linear_nnz": 3470880, "linear_total": 7077888, "nnz": 3479332, "total": 7087872}, "3": {"linear_attention_nnz": 429728, "linear_attention_total": 2359296, "linear_dense_nnz": 3150736, "linear_dense_total": 4718592, "linear_nnz": 3580464, "linear_total": 7077888, "nnz": 3589288, "total": 7087872}, "4": {"linear_attention_nnz": 314688, "linear_attention_total": 2359296, "linear_dense_nnz": 3076048, "linear_dense_total": 4718592, "linear_nnz": 3390736, "linear_total": 7077888, "nnz": 3399308, "total": 7087872}, "5": {"linear_attention_nnz": 326416, "linear_attention_total": 2359296, "linear_dense_nnz": 3008016, "linear_dense_total": 4718592, "linear_nnz": 3334432, "linear_total": 7077888, "nnz": 3343056, "total": 7087872}, "6": {"linear_attention_nnz": 281984, "linear_attention_total": 2359296, "linear_dense_nnz": 2766480, "linear_dense_total": 4718592, "linear_nnz": 3048464, "linear_total": 7077888, "nnz": 3057152, "total": 7087872}, "7": {"linear_attention_nnz": 320352, "linear_attention_total": 2359296, "linear_dense_nnz": 2338640, "linear_dense_total": 4718592, "linear_nnz": 2658992, "linear_total": 7077888, "nnz": 2667712, "total": 7087872}, "8": {"linear_attention_nnz": 200608, "linear_attention_total": 2359296, "linear_dense_nnz": 1736048, "linear_dense_total": 4718592, "linear_nnz": 1936656, "linear_total": 7077888, "nnz": 1945012, "total": 7087872}, "9": {"linear_attention_nnz": 185008, "linear_attention_total": 2359296, "linear_dense_nnz": 707152, "linear_dense_total": 4718592, "linear_nnz": 892160, "linear_total": 7077888, "nnz": 900284, "total": 7087872}}, "linear_nnz": 29954112, "linear_sparsity": 64.7327564380787, "linear_total": 84934656, "nnz": 53891686, "pruned_heads": {"0": [9, 2, 4, 5], "1": [0, 2, 3, 5, 6, 8], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 2, 11, 6], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 5, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 50.50958835936713}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/opt/ml/model", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v9-a4-l40--2021-01-20--19-02-03/checkpoint-105000"}, "f1": 87.31499809166372, "cat_fun_name": "is_full_block", "annotate": "35"}}
